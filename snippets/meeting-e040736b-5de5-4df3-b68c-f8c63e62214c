## Meeting
Calendar Event Title: Onboarding - Using AI Effectively with Mitch
Calendar Event Time: 2025-09-03T15:00:00-04:00
Meeting Note Title:Onboarding - Using AI Effectively with Mitch
Attendees: Mitchell Troyanovsky,Abigail Burlington,Andrew,Jeremy,Kevin,Sachi,Walter,Anthony,Joe
Link: https://notes.granola.ai/d/e040736b-5de5-4df3-b68c-f8c63e62214c

## Transcript
 
Me: Obviously. I think everyone here will probably have different, varying. Theories of knowledge. About how AI works. Different things about it. That's fine. I'm confident everyone will learn something. And I think this is quite useful. So let me bring up. And also, as you may understand, Given. Things change a lot. See if that was. Okay? Okay? All right. Couple things. Why are we doing this? So I think a couple of links, like, number one. We are trying to make our customers most frontier AI based organs in their field. So we need to be the most frontier being out of it all of our field. S whether that be engineering, DI sales, hotels, recruiting, whatever it is. This, Doc, which I think some people have seen, but not everyone. Yeah, that's it. One of the big points. About. We need to move quickly. And so we have to use every tool our disposal to do that. And I think the main point underline here is that the people who benefit most. In this era. It's really getting very good, very fast. Are the ones you have the agency curiosity to constantly be on the forefront. And just to give you a sense of how much I know there's room. I feel like I am probably the biggest power user of most AI tools. And I constantly find myself. Doing something that I'm like, oh, wait a second. I should have just used. Dupify or something. Like that. We'll talk about in a second. Before we go into things, I want to just talk about some business. Did this document readers. Want. The key point I want to talk about is this. So I think most of the reasons that people fail when they try to use AI for things. Is they think of it either as software or as a human. Either. And I think that's the big mistake. So a couple of things to think about. Number one. Is that? Let's just define intelligence for Sam. When we say both humans and AI are intelligent. What does intelligence lend us do? So intelligence allows me to. For example, I think Ilya Saleskeeper had a really good analogy here, which is like, imagine you have a mystery, some sort of novel, and there's a novel like, oh, who is the. It's like a killer. Trying to figure out who's the person who killed the victim. And you get to the very end. And it's like. It's 500 pages. Let's say you get the very end, you read the whole book, and now you're like, okay, the killer is this. Can you predict that? Do you know what that person's name is? Right. Not every human can get that, obviously. Right? That is an intelligent thing to do. That is like. And no software in the world could ever get that. It's literally not possible. For a software. To do. On its own. A human could rightly software that can do that, but a software on its own cannot do that. Right software doesn't think if I did, if statement, if statement will do exactly what I wrote it to do every single time. There's no thinking about it. Right. Humans and models. Can think now. Let's talk about what that means for a second. When I say think, I don't necessarily mean think as in like. All right, I'm going to sit there and page. 97. Most of the time when you do your stuff, we don't do that either. Right. And not even when I ask you a question or like, you know, we ask questions most of the time. Our brain just did something out. We are thinking in a sense of like, we are intelligent. In a sense, the thing we did was not deterministic. Right? We're not thinking. And they like, oh, let me just think through it, that we're going to get to that in a second. There's a famous book called. Fast and slow. Yeah. Thinking fast and slow, where it's like, this is how he writes about this, where it's like, thinking fast is, like, the thing you do in general. Thinking skills, like when you slow down, give a man. She'll process it. Humans are good at both. And we do both all the time. And those are both types of thinking. AI until about a year ago. Couldn't actually do slow thinking. Now it can, but he both did software. Could you either. That's very important. And what that means is that there's actually two points there. Number one. If you are using intelligence. By definition, not perfect. I think it's really important, right? The definition of intelligence and not being perfect. In some sense, right? If you wanted perfection. You would write an instant an if statement is literally perfect. The person who wrote the assignment could be wrong, but the if statement itself will never be wrong. You're not, like, questioning, does the computer compile and the assembly code? Because this. So. Intelligence, I guess. Backtrack. Your. Alex lewton. So just I guess, quick recap there. Intelligence is the ability to make decisions non deterministically. In order to make discernment decisions non deterministically, you need a not like randomly. You need something to do it. That is what intelligence is. There are kind of multiple ways that there's sort of two main ways humans are intelligent. One is this kind of like, I just know. And another is, I'm going to sit there and think about it. So now let's talk about an AI, is what I'm saying. Now let's talk about where they're different. Where are you? In the end of it, number one. An AI Is actually superhuman in many ways. Right. GPT 5. Has a forged token content 400,000 token context, which means I can give it 400,000 tokens that can process that. In 400,000 tokens is they put them are like 250 pages. There's no way any of us could ever read 250 pages in a minute. Let alone. So it's already superhuman. In that sense. In fact, human working memory is actually estimated to be pretty small. Generally. So that's One thing that AIs already have. NS second I'll talk to the second the AI actually knows everything. In some broad sense. So if I go and ask it, it actually knows all the facts about the world? One way to think about this is it's been trained on the whole Internet. And the things that it knows are the more likely. Imagine if you were to read the Andrew Internet. The more often it is to come up, the more likely the AI knows that. That's another thing it knows about. So it's better than us in many ways. What is the worst? The main thing is worse. This is the big. Kind of like it's important is learning. And memory. So imagine, like right now, if we have this, we're having this meeting. Imagine we have the full transcript of this meeting. Here. And we're going to do the audio. And I always ask any of you guys. Hey, what was the word I said at the very beginning of the meeting? Probably nobody does. Because we are not good. At taking pieces of information that are unrelated to this and just like memory. Humans have evolved to be very good. At taking information that matters and saving it down. So if I go in and teach you, like, a couple lessons, you're probably going to remember what you thought was the most important thing from this. At least in the day. You might not a year remember because maybe it doesn't matter at that point. If you might remember tomorrow. Right. If I had an AI Take this whole transcript and run it through. And I go to the AI tomorrow and I ask, what happened? Eating. He has no idea. Because they literally no memory. In fact, when you are working with an AI. That's the key here. It is literally relearning everything from scratch. Right then and there. We're very not used to that. Because humans are the exact opposite. Of that. Humans never do that. Humans always learn continuously. Right. Right now we're talking. I'm thinking information. They're bringing up information. Our brains are literally changing. In this moment. And we're updating. AI's do not do this at all. Now, there are ways to make it kind of do this, but it's more. It's a little hacky. We'll get into that. But generally they don't do this right? So if I go to my chatgpt. Is assuming that they don't have to be like, remember teachers on. And I ask them something, they will not know what I asked it the next day. And so what that means is that whenever you're talking to an AI, if you wanted to do good work for you, you need to give it context. I'll give the very basic example. Imagine that I go and ask. Jeremy about? Hey, what are some good. Examples that we can make in our deployment guides. For one of these accounting firms. I'm assuming that he knows a lot of things. I'm assuming she knows we're talking about basis. He knows the kind of people we deploy to. He knows that one guys I'm talking about. He knows how much they exist there. He knows what our general style is. He knows what I like and what I don't like, sort of. He knows. What the general vibe we're trying to give off to the. There's so much implicit knowledge that he has that allows him to be very good at that. If I go and ask the same thing to an AI. It knows none of that. And so even if it were a genius, even if you have the smartest day of all time, Smarter than everyone in the room combined, it still would do far worse. Because it knows none of that information. And so the key to getting AIC really, really good is giving them lots and lots of information about what you're wanting it to do for you. And that is, I think, my fault. And people talk about you don't want to give it too much context. Almost certainly in day to day use, people are giving it way too little. You almost certainly want to give it far more than you're giving it. So I'll start with that. I'll give you. Let's just pause there. I'm going to go walk through a couple of examples. Come back to it. But before I go on. Questions. Thoughts. On some of this. So about context. Because the one thing always says that you want to make sure whatever the product we're building, Is at risk. Of being outdated by advancing that foundational monitor. You want to make sure that, as a friend, So it gets stronger your part. Becomes stronger. So is that where you think about the context? We build all the context on that. We have all these things that. You know what I'm saying? Is that the idea? So, yes, it is part of that deal. I think we need to talk more about. Yeah, it's partially context, partially embedded, like partially workflows. And partially. As I do those three. Context is most of it. Because what would you think about context is. Yeah, we'll talk about it. I think probably having the right context. Is sort of everything. And I'm talking about this mainly in personal use, like our own use for our own jobs. But it is just as true inside of the product building. Awesome. Okay? Let me go to. Okay, so let me just give you a couple very basic examples to help illustrate. Sort of what I'm talking about here. So. This one shows the most recent traces. I want to show that these entries is better. All right, let me just show you. So. If I did this. I'm going to. Don't do. That. Okay? So I want to show off. And explain this whole idea of the fast thinking not this low. So GBD4.0 older model. This model can't think on its own. So I'll show you what that means. And remember, it knows everything. But I'm telling it's not using tools. You can't do anything. So the only thing it has access to is its own path. Only the stuff in itself. Okay? So it only likes stuff in the set. If I say, who is Miguel Chernowski? I'm not particularly famous. Now, here's what's interesting. Almost certainly in its training. It saw my name at the point price of all running the straight up the Andrew Internet. But imagine like you see someone's name one somewhere. Doesn't mean you remember. It doesn't mean you know who that person is. Right. Whereas if I say who. Is bradley cooper. We don't have to spell it. Let me use the gu. Ys he would use the leverage instance. Who is Bradley Cooper? Obviously it knows. Because Bradley Cooper stainless doesn't seem a lot. And so one just like very, very high level heuristic you think about is nowadays models can use tools. You go to the Internet, so honestly, they're good at everything. But a little bit from back in the day. If the thing you're trying to learn more about is something that is not very niche, almost certainly Long knows it very well. Generally, right? And we'll talk more about it. But if you think trying to learn anything about accounting, about our customers, about data modeling, about Python, about literally anything. The models know what it should be about. You're trying to learn something very niche based, specific thing. Okay? So this is like knowledge. Now, let's talk about the thinking. So let's say I go. And I do Matthew is a very good example of this because. Math is a thing that. Imagine if I asked you to do five digit malification in your head. You probably couldn't do it. If you remember kind of like math from high school, college, you maybe could go on a piece of paper and write it out step by step and maybe you can get there. Without a calculator. So if I go and I'll say, do this. So here's the answer. Via calculator. Okay? If I ask this thing. And ask it here. Let's see if it gets it right. What? Is. 576-240-0182. Correct. But it looks similar. It looks similar. Because. This has been trained on the Holy Grail. If I asked one of us to do this, nobody would know even close. Because none of us have even seen this problem before at some point. But this model is so big. It seems some math somewhere that looks like this. So it's like, trying to remember it. It's like a fuzzy, like, think about when you try to remember things. And you remember the first name that you can't remember. That's like the fuzzy. That's what hallucinations are like, if hallucination is sort of a weird term. But when people remember things, you remember things in fuzzy ways. It's not perfect memory. I mean, it's actually been proven. In many different studies. Actually how imperfect memory is. And so this is the same way to think about the model. Right. The model has seen this math at some point. It's not actually doing the math, and so it's giving you something that looks. Broadly correct, but they're not sure. Probably correct, but it's unsure about. Now let me go. And I want to show you an example where we have a full reasoning phrase. Rock used to do it, but now Brock doesn't do it anymore. Which is annoying. But if I go to. Who does it. Which are the main model providers. Give you. Oh, deep sea doesn't. Communicate. With. The shutterfly. Nice. Let's see if this shows. So now I'll show you the second one. Why? I'll do some checking. Tea as well. But. So let's say now I take this. And I say, What is. Thinking. Now. It might not get the right answer. I don't know. We'll see. It's not deep sea. The Deep Sea Car 1 model is pretty outdated at this point. If I ask this? To while it's doing this. Class is to chatgpt it will get the right answer. Specifically to Chunk should be thinking. Almost certainly not the right answer. Now. I'll see in a second. You'll see. It actually cheated. So it got the right answer. 5, 7, 6, 2, 6, 8, 6, 8, 2. But the thing is, if you actually look at what it did, It runs some python. And so use Python to get the answer. So let's actually say no. No using pine. So Rodent executed code. Right on the flight. So now. It's going to do the same thing. The thing is that what OpenAI does is they don't give you the full reason. Ing this is like the summarized version. So Deepseek, this is the raw information. And so here. 5, 6, 7, 2, 6, 8, 6, 8, 2. We got it right. So it didn't use a calculator. It just didn't math in its head. But it wrote it out. Right. So this is how you get into slow thinking. Fasting something. This is why reasoning model is such a big deal. Because they don't just spit out the first thing they think. If you're a genius and you still have the first thing you think you're going to be right a lot. But if you can sit down and take a step and write it out. You're going to be even better. That's what these models allow you to do. They allow you to reason like this. And the way they do that. Is this. As you can see, where it's unlike deep sea, it's still going. And look how much it's doing. It's doing the math. It's breaking it up. It's, like, carrying it. So now it's adding it up, blah, blah, blah. It's getting to an answer. Now that's what you're trying. Second step. Let's try a bunch of different things. Charging, you do the same thing. It just. It's faster. And because this is a better model, This is a much better model. They just condense this. They summarize it for you. They don't want to give you the raw information. So I'll pause there before we go too. Thoughts, questions? On. So I guess quick recap. So we cover. How What? Models are much better out than humans. Kind of like fast as low thinking how that matters. How they kind of maps. What the models as being weaknesses are. Context. And what are obviously are the main strengths in terms of processing lots of information and stuff like that. Okay? I guess I get questions like that. And you might be getting to this later. Well, you're talking about best thinking. Should we use that same heuristic for? We should be using like GPT5 instant versus thinking versus pro. Great question. Let's talk about that. Actually. So right now. If you go to Chattanooga 5, they have a couple different options. Here. They simplify this little since then? A good way to think about this. Exactly right. Instant is always the fasting. Thinking is always the slow thinking. And autumn is it. We'll try to guess what makes us. And its guess is normally wrong. And then pro. This is essentially like this low thinking, but actually what happens under the hood is it's the slow thinking, but instead they run, like 100 at the same time. And they combine the results together. So this will take, like, 10 minutes. I use pro a lot, like, and what I like to do is if I'm very, very complicated things. You throw it in there and you try to get information about. So I'll give you an example. Let's say I was actually just looking at this. Joe. I was literally just looking at this. Document I had written earlier. So I'm going to take this. And I'm going to. Let's just throw this in the pro for now. We'll come back to it. Later. I have something here. I'm going to be like, hey, can you give me some, let's say, critiques? On this front. Is that good or bad? Not good. Why is it not? Good because it knows no information. About me and Ghidot. So instead, you want to give a lot of context. I like to use my voice. We'll talk about voice in a little bit. So the way I would do this. Is I would do something like this. So we currently have this AI accounting platform, and we sit as this Asian layer that interacts with the different ledgers, and so we need to represent the ledger data inside of our own database. So right now we represent the Andrew ledger. I am trying to make a decision as to how we're going to represent balances. I think that's tricky here, is that obviously trial balances are somewhat different than statement balances. And people think about them a bit differently. They also differ in the three different providers that we currently integrate with QuickBooks. Sage intact and zero. So I want you to read through this and see if you think this makes sense. Think of. Are there any gaps? In my kind of thinking here as to how to do it. And oh, I should have also mentioned that for us, because we're trying to build, like, AI Accountant, it's really important that the latency is really low, which is why I talk about web books in the platform, because it needs to be really low and so that it goes into how we're thinking about this. So give me some of your thoughts on this. And while you're doing that, can you also go and read up on the QuickBooks documentation, the stage attack documentation, and the zero documentation and make sure that the way I'm writing aligns with the way they lay out in their API docs as to how this works. Now, we haven't yet integrated with Netsuite, but while you're doing that, go read about how Netsuite uses their balances and see if the model I'm doing matches with what they do. And see if that kind of makes sense as well. And then take a step back and maybe from first principles. Think about what is the ideal sort of balances framework you would come up with and then compare and contrast that to mine and think about my situation. And whether it made sense or not. So come back to all that. Be thorough. Great. Sound good. What's your information? Let's see if it spelled zero correctly. Because that is probably hard to spell. QuickBooks Stage 3. So cool. I'm going to use Pro. Let me send it off. And you're all just send it off into pro. And it also sends it off into thinking as well, just to show you. As well, and we'll come back to it later. So thinking is probably going to take, I don't know, two minutes. And then probably going to take, like, 10 minutes. Because it's, by the way, going to go to the Internet. It's going to read like it's not just. It's going to go do all that stuff right under the hood. These days, ChatGPT. It has access to Python and Zaxton City Internet. And zaxisolph is, in a way, that's really, really powerful. I could also give it an Excel's PowerPoints and web. So that's example something I wouldn't give them fast. What would I give this fast, right? Because again or instant? Because I might not want to wait around for thinking for things that are very easy. So, for example, if I want to know something like, What's an easy, quick thing? Can you explain to me? How journal entries relate to, I think they're called. Ledger lines or something. And I heard balances. Like trial balances. Can you just explain the relationship of all that to me? That's just the thinking. That's going to think for a bit. That's going to come back to the great answer. While. I like sitting here. And this is stuff where it knows. Of course it does. So instead, if I go here. I just put an instant. Of course it does this, because this is general knowledge. Anything in general knowledge. By the way, when I say general knowledge, it knows the whole Internet. So general knowledge here is, like, real. Like, there's a lot. Even including the niches of different types of accounting and stuff like that, it knows a lot. Now I feel it's going to come back. It's God. It's going to this answer will probably be much better because again, here it's like when thought about it. And whatnot. Sounds kind of a good example. To think about. I generally always use thinking because I'm kind of, like, fine with waiting a minute. But for things where it's just like you're asking general stuff, instant is a good way to go. And sort of relatedly, if you're wanting it to do analysis. The best thing to do is use thinking. Generally. So let me go to my notion for a second. Here. So what are the examples? I have. Okay? Yeah, a couple different. So personal tutor. Research. Let's talk about this. Stuff. So personal tutor. I think this is truly, like, the most underappreciated feature. Many ways you can learn almost anything. If you just want to. It's very cool. Like, most of the things that basically I've learned that I know, I've learned just from Tommy Chacha team, like, literally everything. Like, I need no sequel. That when we started. I think I know sequel pretty well now. I knew. No, even, like, literally, even, like, reachable. To questions on her rhythm. Does that anything on anything technical, anything about accounting, anything about, you know, our current clients, like, literally anything. And you can keep going really, really deep on this. So I'll give an example. Let's say. Imagine I was. Unmute yoursist. Which. Is the key. For a second. And I say, hey, I just joined this AI accounting practice. Sorry, AI accounting startup. And they're talking about their customers. And he keeps hearing the word. People say kaz or something like that. What does that mean? Something related to an accounting firm. Can you explain what that means? Quickly. Now again, here, this is a good example actually, where See, I figured it out that that casm cast, if I ask this the instant, it probably would also figure this out, but like, the odds of figuring out are lower. Let's try. This for fun? But I notice I am starting new chats. And not doing a second chance. That's another point. Like you should generally not do the same chat for different topics. Because then it has to use all the info from the topic above it. To answer it. You just make it worse for no reason. Is there any issue with using the same chat, changing the model? No, that's fine. Too. As long as it's the same topic. It. Got it right. That's interesting. Can you tell me more about that? Like, why do they call it Client Accounting Service? Where did that come from? It's kind of interesting, is it not? Just like accounting or bookkeeping. What's the difference? And you can just go deep on literally anytime. It's pretty incredible. It's like having a custom Wikipedia. For a friend. So yeah. But that's, I think, what's quite cool about. For things that we're, like learning. Anything you want to learn is very regular. You can have a critique. So that's one. Personal tutor. Yeah. Asking questions. Just, like, general stuff. Good. Search, I think research and search. Now I pretty much always use this and not even Google. What I want if there's anything complicated at all to search for. Because the key here is when it's going and searching, it's not just hitting Google and summarizing the results. It's going and actually looking at it coming back again. It's like an example, let's say. What's example? Let's say. Let's do examples. Is it like an accounting example and a type of. So maybe an accounting example. Would be something like. I'll throw this one. Trying to hire candidates. All right. Go through math companies in New York. Series ab blah, blah, blah. You do that? Let's say it's going to kick off there. Then let's say I want to do some research on. I'm trying to understand the universe. Of what? Bill pay platforms. Are used. In cash practices. Across the country. So obviously I know what the big bill pay platforms are. On and ramps and expensive, et cetera. Can you see if you can find any sources, information, things like that? That would hint at which of these are generally more popular among the firms. Which ones have, like, active accountant channels? If there's any other evidence of them being really used across different accounting firms. And let me know not just those other ones as well. Let me know which ones are really popular. And maybe try to create your rank order from your best understanding based on everything you found. As to what the most popular AP platforms are among CAS practices in the United States. Again. I'm talking because I liked it. I prefer to do that. But you don't just write. Okay? Let's do, like, a technical one. Quickly. While it's going off. A fun, technical one. Could be something like. Let's do. Just going to think about API documentation. Now. I think we related to brainstorming, too. Right? Like I could say something along the lines. I'm trying to make a decision. About how to model our journal entries object, and I'm trying to understand that. Can you go and look at a bunch of the different ledger systems exist today and look at their API docs and how they do the modeling? And the thing I'm particularly curious about. Is on the Journal line. Within the journal entry. Would you expect all the other dimensions? Like vendor and account and tracking category and things like that. Would you expect that to be everything to be on the journal line, or do some of them belong in the journal entry and which would belong in each one? And how would you do that? Can you go through and summarize. Summarize all that for me? Like how other people do it. And if there's a couple clear options, maybe break down what those options are in the pros and cons of each. Okay? We'll do that. Let's go to some of the things. That came back. Okay, great, so. This is the. Thinking. Let me see if I throw one. This is a good example where literally yesterday. This came up. Someone ran in the chat we were talking about. Do we use the posted date or is it transaction date? And I've done this research records it. We used it for Zif reason. I just wanted to double check that. For big transactions. Should we use the transaction of implicitly, like what other people use, and it's like, very clearly, okay? You're supposed to date because that's actual date doing. I'm finalized. Here's how differentiates we collected and give you all the links to their docs and everything. This is the kind of thing this would take 20 minutes. This is like instead, it doesn't even take two minutes. It actually takes ten seconds. Because you just put it in and then you go do something else. So the series actually kind of ridiculous. I think about. In terms of your time. Where are the other things here? So this was the. I believe this was the pro. Delicious. So here it went. For four minutes. Let's go. Open noise. Understand how the different vendors do things. Thinking about it kind of clearly. Just about proposal. Answers to my open question. I'm not going to go to these right now. And then I can follow up and give you timeline. It's like, very, very good. So these are kind of things that you can do. And as you can see, I'm kind of, like, combining a couple of these. I'm both doing research, and I'm doing brainstorming. That's what I. All the time. I do this all the time. Because it's like imagine it's very useful to talk through ideas with somebody. Here you have somebody who's always willing to talk to you. Will always listen all the time. Which is amazing. A couple other examples. We just show. These are still going through. I think. Maybe. All right, let's go through a couple other points here. Okay? For those who want the voice. Some people like it, some people don't like it. I believe everyone might have already got it or haven't you access to do you want. It's called whisper. So what's cool about it is that you can just kind of talk into it. And it's like, because you can talk to it, it makes it really easy to keep lots of context. You can write everything out. But. But, like, typing is just way slower than talking. And the beauty is that when you're giving something to the humans, Because people are. Like, we're not good at reading two pages of text. That's why writing is so key. Like, good writing is like, where can you. How can you communicate as much information as you can? And it's little words possible that is very, very hard. And models are not that good then. For models. That's not that important. It matters more of, like, larger scales. Like you want to, you know, but if the difference between me giving them something that is like three sentences versus me giving them 50 sentences, not a big difference. And so I can just talk and have a bunch of filler words and, like, say stuff and they will not complain to me. They will still get all the information. So you don't need to write perfectly. For that. That's what's so nice. So anyway, I just whisper for voice. And you can actually just talk. And it will transcribe it perfectly. It'll do some formatting, too. Like, if you do something like. Okay, so we have two ideas. One, let's start. The session. Two, let's use more AI. Three, let's use grill. So I like that. Some people don't teach their own. Okay using boys. Okay, a couple things here. This is true, I think, mainly technically, but there are some other points here. Is that because you should sort of assume when you're working with models, That they're always missing context. That's always true. There's no way it has all the context. That it needs to solve the problem that you want to solve for you, because if it didn't have all the context, then it's probably going to give you genius level stuff. Because it's already very smart and knows everything and whatnot. So always the content. And so what that means is that because it's almost the context for your own purposes, It's useful not to ask for an answer. But to ask for options. Because maybe its first idea is not correct, but maybe it's fourth idea. Is. And you will have other context that people will not have. So it will not have known. Like, if you say, give me one answer, maybe it's fourth would have been right, but it didn't have some context that you were missing in terms of why one is better than the other. A coding example would be like, oh, go. And there's this bug, like, go in. What are some. Why is this breaking? We just say, why is it breaking? Is it going to get it right? Maybe, maybe not. But it doesn't know how the server works. It doesn't know the way the deployment is. Missing a lot of information. And so we might not tell you the right answer, but if you say, hey, one of the top three reasons is good break. And then it gives it to you. It's like, oh, wait a second, it's definitely three. Because I know something that it didn't know, right? But that's true for everything. That's true for writing docs. That's true. Anything you do when you're kind of brainstorming and so anything where you have a problem, you're trying to think about it. Like, hey, I'm trying to come up with something, kind of help me out. And so I think generally it's really, really good. For that. Some examples here. Some thoughts here that I think most people don't appreciate that it's very good at is remember it can write code on the fly for you. Which that means that's actually a very, very good data analyst. So here's an example. So I actually had eight generators. For me. But I have the CSV here. And it is a fake, like recruiting funnel. As a source and role apply. And everything. So I'm just going to go. Quickly. Here. And just be like, Can you go through this recruiting data and organize it for me? Let me know what the key insights are. Create a graph for me that shows how it's gone. By category. So buy different source type, what are the different reits? And then importantly, can you come up with three potential suggestions of how I can improve my perforating process. To be more efficient and get higher signal candidates based on the data that you see. Now, this is a great example where if I wanted to ask this instant, it's not going to do that really well. If I go to the auto, I think it'll probably be okay because it'll know to kind of, like, direct. That's sort of how it works. See what it got on the build aid research. Question. That is true. Fun fact. It definitely is the most used AP platform. No question. And so far, I've literally only seen these two. In these big firms. This seems reasonable. I think it's like, one, two or, like, way above, and then it kind of goes down. Those were the nine. I would have said these nine. Yeah. That makes sense. So quick. And the slices that you can just dig into any. I think that's the key. You can now go down any path. You want? On terms of. In terms of learning. Things like that. Here we go. So. Oh, this actually. This is actually great. So just so you understand what happened here, so if I didn't do this. So it went. This is like, why these days. This is itself an agent in some ways. They went and did this work. Okay? It came back. It rode this python code. And something happened. It failed. Okay? Now, I suspect this is like a bug on opening eyes in. Not the agent's fault. But it had an issue, some import error. So it's like, oh, shit. This didn't work, so I'm going to try again. And it's going to use that error to now do something different. Let's see. If now it's going to get. It. Maybe it imported the package and it's like, oh, that package. Because remember, it's inside of an environment. It has a container. That you can access as Python code. And so you try to use some package. That package broke, so it's like, okay, the package doesn't work. Let me try these. In some other package. And it can go iterate. Right? These are like the tools it has available. As this folders are going to do it. So now, here. Let's try again. So you can see what it's doing. I'm going to go inspect the data first. So just get data scientists. I'm going to print the first five rows. Just understand what I'm dealing with here. All right. So this is what the data looks like. Because you want it. I didn't tell them what the columns were. Right. So it's first going to look and understand what the columns are before it writes other code. It needs to understand what the columns are. What are the types of text? Things like that is literally exactly what a data scientist would normally do. If I told it the older context, if I said, hey, here is, it is, and here's what the columns are, maybe wouldn't do this. Right. But it's doing that because it doesn't know. This. Is a lot of finally time to get there. I don't know what the package was trying to do. Was. Okay, so it's getting to be some. Sort. Of space accounts. Conversion. Tables for me here. Now I asked it for some graphs. I think here it's probably going to try to make the grass. Now it's going to make some charts. Using Math Lib. This is the charting library. So now it's going to use some charts. With the column number in. All right, now make a chart. My source. Type. Look at this. It will kind of cancel. But doesn't it? The point is, this took way longer than it should have because of the error. Which would not normally happen. Funny enough. We have some errors open at the moment. That might be related to this. But generally, the way think about it. Could do a lot of different things, like, more things than you probably appreciate, and I think you should generally always just try. In terms of interior. I'm not missing. Anything. Set the analysis. Okay? Let's start with writing briefly, because I think this is a classic. I think that. Good writing is very hard. And good writing also requires lots of context. The vibe you're trying to give off. What's the type of who is the audience? What's the writing? What specifics there. You can get the AI to potentially write good things. Very small now. So for me personally, when I use it for writing, I don't think it's actually quite good for writing Andrew things up. I think it's quite good for scaffolding things. And then for helping you iterate on specific areas. Let's say I have these two sentences. And I'm trying to find a better way to save these two sentences. Or let's say I have this, like, two paragraphs, and I'm trying to find a way to condense it down. Things like that. Are good ways to get to the accidents. I think for writing that it's less important. Really important for me to get super well, like maybe the doctor is not important. It's good for reviewing and it is good to generating something. But again, to do it well, if you give it a bunch of examples, hey, here's like 10 docs that look like this. Now write one about this information with this. It'll do that quite well. But you want to restrict the degrees of freedom it has. Like, hey, here, 10 docs. I want you to write it like this. And then here's a really poorly formatted piece of information. Write the doc. Then you're going to do it, okay? I think another better way to do this. Use it as. Use it as a reviewer. This is only how people don't do a lot. So, for example, on documentation is a really good one. If you go and you throw it in some docs. And you say, hey, imagine you're like a new joiner or an accountant or an engineer in your journey, and you're reading this for the first time. What's confusing? What? Does it make sense? Right? Like you can use it because it's an intelligence. Use it like an adult, right? Have it be that thing that goes and tries and looks at it and things like that. And you can create many loops of interactions. Here. Come romance. Any other thoughts? Questions. How does a lot of this. Relate to. I think we talk a lot about AI in the code base. Had a lot of this relate to Matt and Matt, this team. We'll talk more about it. But there's already a repo called Atlas that actually has. Most of the external documentation. And a lot of the adrenalines as well. We'll figure it all. Out later. But probably the way to think about it is because context is so important. We need a way to manage context. To properly build the agents. And the context. In some sense the most important part. Like the agent stuff is much easier. The content part is the hard part of them. Like, even right now. I mean, look at this week, right? We've been making iterations. On how workspace works. We're making iterations on how the bank statement ingestion works. Agent there. We think it changes on the balance extraction. There are going to be updates to lots of things. All these are agents. The hardest part of all that is not the code, right? It's the context and the evalves. Because at the end of the day, that is what matters. Code writing is easier. These days. So here. One thing. I'll just still need to find the word even. Here. I think the easy way to understand the word. Is Egypt is when you have agency. To do something. You are giving it the freedom to do what it wants to do. If I go to gpt4.0 just now and I give it something. And it can do it comes back. That's not an agent. Because it doesn't have any agencies. It has to just come back to me. You saw it just now. Reject thinking. It shows the right code. I did not tell it to write code. It chose the record. I said, analyze this and it shows the record. That's agency. It has things it could do that if it chooses to do it will do. And then it got an error and it chose to now try again. That's what agents are. Agents are when you give intelligence. Models. An environment. In that environment has tools. And you give them the freedom to decide what to do. You have to give them guidelines and you give them restrictions. And there are certain things you can do and can't do. An environment, and by definition, you don't have total freedom because you have an environment that's constrained to your tools. Like, for example, you can't write JavaScript because there's no JavaScript container in there. There was a place on container. But there's agency and so that is n't. So. Egypt is not a binary. It's not like, oh, this is an LM on its own and this is an agent. That's not a thing. It's always a spectrum. Because it's always about what is the amount of agents you're giving, for example. Today in basis and for the foreseeable future. There is one type of vacancy. We're not giving the models, which you're not having. The agents go into external systems. And make changes. That are outside of basis, right? When? Right now, actually. In workspace, for example. When I have the agents think a journal entry. It has the ability signature, but its ability to sync a journal entry means it is using basis software. To sync the journal entry. And then the base of software has all these checks and decisions and stuff. To make sure that the thing is fine before it sends it over into the ledger system. You can imagine another world. Where you just say no. Here's a quickbooks API key. Here's API. Go seek a journal entry. That could happen. That probably will happen. In the future, but today you don't give it that level of agency. But that is purely. That the design decision. That is a design decision. As to how much agency you're going to grant the model or not. That's all it is. And the key here is because these models, because they don't actually learn in the way humans do, they do learn in some ways. They can talk more about this later. But they begin to go learn the way humans do. They can't actually do tasks. For that long. So today, probably the most complex, long task you can do without getting overwhelmed. Like an hour. Maybe a little less than that. 45 minutes. Of it working. The state of the art. The most recent OpenAI win at the math Olympia. It got gold medal. And in that case, the model worked on its own for, like, six hours. But think about any of us. I mean, we can take a project. And work for a month. And not get confused. Right? So that's the big difference. Between humans. And. Today. We can work for a long, very long rises. And getting more and more complicated tasks. For buyers working for longer and longer horizons. And the models are getting much, much better than that right? Today, GB5 can work for X length. A year ago. Let's say it can work confidently for 45 minutes an hour. There's not totally true. It's probably more like 30 minutes, but you can go further, maybe like an hour. A year ago is probably like five minutes. And next year. And that's, like, the difference. So you can have these things you can do more and more complicated. Tasks. Which is why like you have certain like. That's why the task today that you give on agent is not go do the month in flood. It's smaller, it's good to the month and close the much longer large task. But it can be pretty large. It can be like, go do this Andrew task. In the month end post, which is much larger than hey, write this one email. Until you have these kind of different steps. All right, last thing. I'll just show you quickly. Before I need to run is. You're just taking notes. So this is a Granola, so it's never used it. So granola does it just records a transcript? It does not record the audio. It's just transcribing. And so if I can get my computer notes from here, it's going to go and analyze it. And it can generate guts and then you can make templates for it to generate notes. So right now, this is using its auto template. So here we pretty much, for those of you use this in pretty much every internal meeting in British every external meaning. And you do this. And the reason this is very valuable. Is because. Let's say you forgot something. I can come here. And then they're auto input. I could say something like, what did we say about. About? Or your husband. What was the example used to illustrate. A person. The models now. So here's doing it by auto. I have in here different templates. And you can make templates. So if you go to. It's actually the UI spons. Or. Yeah. If you go here to new template, You can define the template. For example, let's say you always have a certain interview. When we have a customer conversation, you could say after it, I always want you to generate these five sections. What did I say? What are the takeaways? What are this? Are you going to always be like if you don't try to do opinion? So it's up to you to kind of what you want to do. I generally don't trust Granola like I don't trust how they do things. So I prefer to just always take the transcript. You come here. And just do, like, hobby transcript, and then I just go into judging teams. I'll be like, Can you take a look at this meeting? And try to think from first principles about what this means, about trying to learn how to use AI and understand basic agents and sort of go through it. And come up with some things that I could have done better. That could have improved. This more. So I'll give you both the transfer of the meeting as well as the document that I was showing on the screen. Along. So I'm going to do it here. So I just did that, right? And then I'm going to give you the transcript. Copy paste them. So here does a transcript, and I'm just going to just organize this a little bit. What I'm going to do is I'm going to use markdown. Here, which is like a title. Like your job. You don't have to do this. But just organize because I reference the transcript. And I'm just going to go below here. At the bottom. I'm just going to give it another. If you do command, enter into spaces. Hashtag. Notion. Shown. And then I'll just copy paste the machine. And by the way, they do this funny thing where you can, like, skip to do the fast version. Which is interesting. Ux. Not true. That could be right. How many equivalent pages is 400,000 tokens? Interesting. And by the way, do you give a good sense just so you understand how much the content's window is. We could have run if I had to last the train. I should do the transcript. In the last 10 times I run this meeting, I can dump all of them at the same time. And just have it go and analyze them altogether. You can give a lot of information. And almost always people are underappreciating conscient information, and it's always better to just dump it. If it seems relevant. 