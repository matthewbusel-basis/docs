## Meeting
Calendar Event Title: Product eng interview process
Calendar Event Time: 2025-09-09T14:45:00-04:00
Meeting Note Title:Product eng interview process
Attendees: Ben Katzburg,Neville Jos,Abigail Burlington,Ashley Wong
Link: https://notes.granola.ai/d/1cd81fdf-b082-49b9-aabc-140a2ed3b8d6

## Transcript
 
Me: So you want to know how the product engineering interview process works? Yes. Ben, is there anything you wanted to add to this process, or are you just joining or. I wanted to hear what you had to say and also what you're planning on changing. Because we're about to change the interview process. We're not going to do that in this meeting. I think we're just going to describe the interview process right now. The changing one will have. I want it still have Chandler in that. And then have the other engineers. We're just going to describe it. Yeah, useful. To here. Okay, for context, I'm making a guide for Jessica. Then you're recruiting offsets. Amazing. Okay, great. Okay. Does someone have Granola? Abby. Perfect. All right, let me find old docs. What is our product engineer? Okay, let's start with the. Okay? This is how we used to teach interviewing. So. Do you have anything to share? On the screen. Oh, should I? Know we talk about. Could you turn on the tv? Okay? So at a high level. We have a thing here, basis, which is like, we hire on trades. So we believe that any person we hire should have six traits. In order to work here independent of the job. At some level independent of and that could be anywhere from DI to sales to office to the CEO to engineering. Everyone has 56 traits. Partly because I think that as intelligent as someone is, startups are extremely emotionally hard. And painful. And there's only actually very, very small set of people who actually enjoy that kind of work. Even though people think they might. The truth of actually liking it is very hard. If you've done startup work, you actually know how terrible it is. But people who've never done it actually don't know how terrible it is. Right. And so, and for us, if someone especially hasn't done worked at a startup, especially early stage startup, and that's not really the experience, then we have to play a game called how do we know if they would even be good at this. Or like this. You know, it doesn't matter how smart they are. Some of you would have to. They would have to. You know, they might have a hard time with it. And so the traits we've come up with are these six. Wants to learn. Like, are they curious? Are they defensive? I mean, you know, at a very high level. You can imagine that I've said this to company before, but no one here has built 100 billion dollar business. We literally don't know how to do that. And so by nature, we have to go learn something new that we do not know. And every single person here has to do that. And so we look for that as a trait. A few ways that we try to see if they do. This is one we literally say, see if they say the words I don't know. In the interview. Which I try to challenge people into. Kept saying, and you'll see often that people just don't want to say it. And if you can't say, I don't know, then you would never. You'll never know. Because you need to start with I don't know, to know. And you'll also see how defensive someone is about, you know, if their last company failed, for example, or something you might say, like, what happened. And they start blaming everything else except themselves. Then that's also a sign of like, wants to learn. Because if a company failed, you were part of the company, then you contributed to the failure in some way, shape or form. You were not insulated from that failure. You were a participant in that process. And so if that's how you see somewhat defensiveness, and all that stuff. Matrix, and I like it a lot, which is that he said that our interview process is akin to being a detective. You're meeting a strange person or whatever. And you don't know their entire life and you have very little time with them. And so you are doing detective work in order to identify and build a profile of this person. In those small amount of time you have it. And so every question, every moment is filling out that profile. If you know that they have a good ones to learn trade, then you have to ask no more questions about that trade. You go to the traits that you are least clear about. And you just start building up a profile from there. If at any point, any of the traits that are not, then the interview is no. And then you can call it. That wants to learn. Can intensity, which is like, do they actually take work as a part of an important part of their life? And something they want to build and water as a plant or whatever. And oftentimes you say, and again, I have no issue with this. But people think that people see work as a thing they have to do for money, which is also true, which is there's a lot of shoot for. But in that start of being exceptionally harder than not, there's better ways to make money. Than coming and being sad at a startup. And thinking that it's going too fast with Coutur. And so we try to see people who like the intensity and the difficulty. First, most people say good. This is probably the hardest to find. And also gauge. Earlier. For example, when we're talking about Atlas, we always start with a set of beliefs about the world and the structure. We say this belief leads to this belief leads to this belief. And because of that, That's why we're going to do this project, or that's why we're going to do this random Excel spreadsheet thing. Or every single action at some level or is the best we can. Should have a set of beliefs that go out of that. Can be clearly articulated. Which is actually very rare. I think that startups just do a bunch of random shit, hoping that one of them works. It makes the money, which is just like lottery game. And sometimes it works, sometimes it doesn't. But the thing that we really prize ourselves on is, like, being like, what is the belief? That's like running this decision. And if you cannot clearly articulate the belief. Or the principle or the whatever behind what you're about to say, then. We shouldn't do it. That's a model. And oftentimes, at least with mad vision especially. We don't talk about the decision. The decision actually, in a lot of ways, doesn't matter. We talk about the framework. You say, like, okay, I believe in this, this, and this and this. And the math will say, this isn't this, and Mitch will say, this. And now all the beliefs are in the air. And then we debate about the beliefs. And evidence for the 1 until we find a shared set of beliefs, and then we come up with an idea that is both from the shared set of beliefs, and so we'd like to emulate that. Process also in our interview process to see if people do that or not. So that's one of them. Agency. Can you. If I left you alone, will you do amazing stuff or will you be waiting for instructions? And do you really believe in your heart that you can change the world? Kind of like, not in a granules way, but in the way that you have agency. You can go change stuff or you're waiting for someone to tell you what to do. And so agency is another trait. Confidence is an interesting one, which is you can't be underconfident or overconfident. You should be able to very clearly say, I know what I know and I don't know what I don't know. And so being under confidently. You talk a lot. And then smile is the last one I can. We spoke about this yesterday. But it's like, literally G file. This is a very stressful place. I think we do a semi decent job of keeping it on the lower end of the stress total. Not that we individually don't get stressed at times, but the overall place doesn't. We try to make it not fully stressed. This is also a marathon. And so can you manage your stress well and do your practices and systems of that. And so interview is actually very interesting because I love interviewing. It's probably my favorite thing that I do with the company. And interviews are inherently stressful. You want a job? I have a job. I'm going to ask you these questions that are puzzles. And so it's actually the perfect place to see someone smile. Almost do anything. When they show up if they're not smiling. You can tell. Something. Anyways. So those are the six trades. On each of these, we give it a score from a strong no, no yes to strong yes. And then, you know, most people are have to be yeses. Almost all of them with some strong yes is mixed in between. We actually rejected a few people because they were just soft yes. And everything. But they feel strong. Yes. And a few of these things, they need to have some spikes. After you've passed these six. And often, sometimes when you talk about candidates and we sometimes get into practice and out of practice. But if you're a lost world, a candidate, and you're like, I don't know if I like this guy or not, or whatever, It's helpful to just go through this list and we'll just say, yes, no. And it'll actually really help clarify the thought process more than anything else. And then during each interview, if you can just hold it or maybe mentally note down, like, these six traits, then you can generate questions. From that perspective. Than anything else. Like, if you think someone's not smiling. I literally go. Said, like, hey, are you feeling anxious? On this. I'll ask that. They're building anxious. That's fine. And then we'll see or feel like our. Agency is another one where it's like a lot of stuff like, oh, yeah, what was the teen structure like, what this idea come from and how was this built? And sometimes people will start talking about how amazing their senior engineer is and how the senior engineer made all these decisions. I'm like, oh, okay. Where did you see yourself contributing? And then you could kind of tell that they didn't do anything. And so in terms of idea generation or execution, Trying to think about anything. Else. Before we go to product and specifically any questions. No. As a suggestion, we might want to add this to onboarding because this is just a helpful thing for even if I wasn't doing interviewing, this is helpful to join basis. Yeah. Matt, Mitch and I sat down. It might have been a year ago. Where we were having all these mixed reviews and interviews, and we were like, spend a whole weekend. What are the six? There's some other ones for, like Di, I think, like being more detail oriented, process oriented, which doesn't affect engineers as much. And, yeah, they added some additional ones, but I don't really think about them. And then we get into the core ideas of, like, after you pass the six. Like, there's mainly, like, three things. One is, can they do the job? Pass the six trades. Great. Now, like, what's the job available for you? And oftentimes we'll actually pass on on six straights and then try to figure out what job they could do as opposed to trying to match them to an existing job. But I feel like someone will try to figure out something to do with them as opposed to, like. So that's why he comes after. It's not the most important thing. But can they literally do the job? Like, are they. Can they code? Well, can they di. Well, I'm not sure how to do that, but, like, you know, accounting. Can they, you know? Another thing we look at a lot is slope. So slope is kind of tied to stuff, but it's like, you know, there's this. There's this element of like, you know, do you have these six traits? Which is. Which is. Which is usually like, either it's kind of like, defined early in your career. Like, I kind of believe that, like, postcology kind of start to have most of those traits locked in a little bit. And. And so we either can battle on that level or not. And then slope is like, okay. Can you do the job well? Upgrade. Like how? How long does it take you to learn how? Learn all the stuff, you know. So if you're, like 15 years into your career and you're as good as someone who's five years into their career and you have all the trades, well, there's not a lot of slope there. So that's kind of a negative signal. But if you see someone who's like 20 has done a lot. But they're, like, bad. They're kind of, like, bad at the job. They have all the traits, and they've learned a lot in the last six months. Like, you project that on, you're like, okay. They'll be fine. You know? And so we make some. We make. Sometimes we'll make something a slope higher, which is like someone young, hungry, doesn't know what they're doing, so they almost can't do the job. But they have enough slope that it actually makes up for them. And so those are other things we test. And slope actually is really simple to calculate. It's literally ability gained over time. So you just gauge the level of ability they have divided by the time of their career, and that will give you some math on whether or not you think it's high slope or not. And this goes also into learning, which is like, you know. If we're growing a lot as a startup, then high slow people will keep growing. And if you have low slope, that's not actually the worst thing either. If you can do the job, that's great, but it just means that as the company grows, Exponentially. Your job won't change that much. And, like, we'll add more people around it. As opposed to expecting you to grow. Okay. Is that helpful? Okay? Great. So now we can go to product and specifically. Right now. Our product engine review process is. Well, they talk to Mitch first. Mitch has a set of criteria that's not even the core six. I mean, he kind of gauges it, but even there's just like. Do you literally want to be in New York City working in the office? Five days a week. Like that kind of stuff. Do you actually, like, want to be part of a startup? Or not. Like, very little. I think he has a lot of, like, variants. I don't know what his actual interview is, but I think there's a lot of literal questions. And, like, high level. What have you done? Then they go to. No, they start with the event. Right. Or me. Then they go to mention. Then they go to Match. But I. I took over all those questions for him so he could just have a good conversation. Like, dig a little, technically. Right? So he goes, yeah. Ben. Mitch. Mitch does a little digging. Then Mitch sends them to usually me or Ashley as a number two, actually. And we do an hour long interview. This actually thematically. You know, this actually connected to the conversation we were just having, which is that, you know, if you really believe that the future of engineering is AI writing 99% of the code, Then the job of an engineer is coming up with the ideas of what the AI Is gonna write. Not actually going and writing it. And so that drastically changes the way we interview people as well, because then our job on a daily basis is so much more talking with each other and sitting in rooms and just talking, talking and talking way more than it is. Like, literally doing the thing that needs to get done. And we believe, even if that's not true today. Fully that I've never spoken so much in my life, in my, like, the way I work. But we think that, again, as Atlas grows, things grow like that ends up becoming way more of a percent of you doctoral. And so the thematically, you know, product engineering, specifically, we look for how collaborative are they? Like, do I literally wanna sit next to the sky? Or this person. And spend 10 hours talking to them. And the next day be excited. They talk to them again for another 10 hours. You know, do I wanna slowly strangle them? And that really defines, I think, a lot of the engineering interview questions, specifically, thematically, Heavy emphasis placed on collaboration. So we do a 30 minute introduction, we skip their background, we'll answer some questions, we'll do some lights selling. And then the next 30 minutes. Our first collaborative exercise. We should do with product engineers, which is this thing called airport. 100, 800 billion. Yeah, I did. For an engineer. Just collaborate. The way I describe it is literally like so much of our days. Like, people rolling around the chairs, coming to you would be like, I have an idea. And we speak for 30 minutes. That's literally what ends up happening. So how can we recreate that? In an interview setting. So we talk about airport for a while because it's actually an extremely hard interview question, because the rule of airport is the interviewer has to also come down and sit in the chair next to them. And not be challenging them, but actually collaborating with them. And so you have to show up in collaboration, not as an interviewer. Like if you show up as an interviewer, that will incentivize them to show up as an interview. Ee, which introduces a power dynamic which actually doesn't allow you to gauge whether or not you want to equally interact with this person, which is what we're trying to emulate in the first place. And so you're not trying to question their intellectual. Whatever. Rigor. You're literally just, like, hanging out with a person for, like, 30 minutes. And, like, that actually takes. It actually takes a little bit of training. I know Ashley talking with him. It takes a while to like. Because we're so used to interviewing people in them testing. We don't test people. I was just seeing. People are smart. I'm not trying to test them. You know, I'm just like, I just met you at a party. Like, we're here for, like, 30 minutes about, like, a topic. Like, how does that feel? Do we like talking to each other? Do we like the ideas that each person bringing in? Like. Does it feel like a good back and forth exchange? Some people are aware of. Dominating and domineering is just fun, okay? This isn't gonna work for us. Some people very quiet, and I go, is that gonna work for us either, you know? So how do we. How do we do that? Airport. New tournaments of that. Then we do an hour long of coding. We thematically again, because our goal is to try to figure out what it's like. To work with each other in the office. We give them problems in the office that we had actually. So something that we literally had to do. And we give them all the tools. They would have in the office. So they can use cursor, they can use the latest models, it doesn't really matter. Interruption. For those in the studio audience, can you give us a little bit more about airport? What is important? Great. Airports are very good question. Sorry. That's a very good question. Very simple. I'm describing an app idea. I'm like, a product person, so I don't know how to code or something, but I have a cool idea. And you're an engineer, and I'd love to hear how you go about making it. Even if it's possible to make it, maybe it's not possible. To make it out. And the app idea. Is. I've had layovers. At an airport. Just sitting at the airport. For, like, 10 hours. And I'm really, really bored. And so instead of an app where as soon as I land at an airport, I say, hey, I met, like, jfk. I've got 10 hours, and I've got, like, 300 bucks. Tell me what I can do today. And the app says, okay, we'll take an Uber for $65, go to this pancake restaurant, eat their blueberry pancakes. That's $18 with taxi tip. Then go to a park, walk for 25 minutes around the park, then take another Uber for $34. Or we'll play a ticket. To earn $5. We'll watch the play for an hour and a half. Then go from there to a bar, order Necroni, so on and so forth. They'll just tell you exactly what to do with your day. Fill it up and then gets you back at the airport and the time you want to get back in. And that way you have a mini adventure in the city. Then, like a boarding day, sitting at the airport. So question is, how would you go about the. And there's no, like. I mean, we have like a. This is the hard part, which is, like, there is. We have a. We have a correct answer almost. Well, it's not even a correct answer. After doing the interview, I think almost 200 times. Like, I've heard every variation of it, so I kind of know at least the best version of the idea right now. If someone said some crazy things, sometimes someone says some, like, crazy thing, and that's the element of collaboration. When you're interviewing airport, one of the hardest parts is because you have this, like, notion of the correct answer in there. There's this intuition to want to guide people back into it, but that's not very collaborative because now you have the answer and the other person doesn't have the answer. And so there's power dynamic again. So if someone says something crazy, You actually have to play that game with them. It's play time for 30 minutes, and so you have to follow their idea. You know, and if you don't agree with it, you can debate it from. Not from the correct answer because of your own convictions. In something. As opposed to being like, oh, well, let's not talk about that. Let's talk about this. You know, China artificially guide them back to whatever you think the right answer is, because then they feel that, and then that doesn't have fully collaborative environment. So we're trying to build, like, 30 minutes of playtime. And so try to see what it's like to really, which is, like, a lot of work. Is there any coding in this whatsoever? There's no coding in airport. And we can do it both with product manager roles and engineer roles. I've done it with my sister, who's in marketing. Like, it's fun. It doesn't really matter, like, where it goes. It's gonna take, like, it's just a conversation topic. So it's not like there's, like, you know, if she wants to talk about marketing the app for 30 minutes, that's totally fine, too. Get to learn a lot about her in that. In that exchange. Is it more how the app it works in the back end of it. Yeah, a little bit. Like, there's elements of it. Like, I'll ask something. Like, you know, it generates an itinerary. You know, like, how do you know it's a good itinerary? Like, what do you think is a good item? Like, I'm. Where do I give this app to random people on the street? Like, I want them to love the app. I want to open the app. Look, that channel. Go. Wow, that's great itinerary. How would we know that that's gonna happen? And, like, everyone has an opinion on that. Like, you know, you should serve food and. This is just sending a doll. Cabbage. It, like, has basically a pressure. All right, well, bye, everybody. Thank you. Oh, yeah, I forgot. You wrote this gigantic guy. But most of those helpful. Yeah, it's a. I mean it's a very hard. It's a very. That has a lot of the information. The real difficulty of inter visa basis from our perspective is showing up and not a power dynamic which I think a lot of people feel. And which is why. Which. The reason I also want to do that is there's multiple reasons why. There's also what makes people want to join us. They feel a different energy, and they don't feel that power dynamic that generally exists in interviews. And they go, whoa, this is actually fun. The amount of times. The amount of times people go, I really enjoyed that hour, independent of whatever the job is. I'm like, yeah. That's different. It feels different. And so that incentivizes for people to think about basis. That's more of an option. Than the classical. Like here is like a Busel and do my puzzle. Whatever. So anyways, and we liked it thematically. Do that throughout the whole process. And so, you know, when we're doing the next coding interview, same thing. Collaborative. You can use AI you can. Whatever. And so, in that, it feels more not a power thing and more like, let's discover each other. Like, do you. I always ask people, like, do you like us? Like it matters. Like, you can look at me and go, fuck this guy. And I'm great. Like, then we shouldn't work together. And in interview is a two way street. I think people get into the power dynamic. Of like, oh, I need to get a job. But I'm like, no, we need someone to do the job. So I'm actually coming in a vulnerable state and saying, I have a weakness. I need people. And so there's equal exchange. In this as opposed to it being one way. So we do coding and then we do four hour on site and then the on site has. Usually we mix and match in the Cisco chitcha right now. To be honest, but it's usually two not coding things and two coding things. In some way. The show part of it is we kind of mix and match them in no particular order. With no particular strategy. Those are the system design. There's always a system design that's consistent. This one this morning. Someone's coming in today, for example. And apple juices is example. Yeah, it's actually a great example, but for this person, we ended up designing people. Interviewing so many different things. This was also mentioned in Skirting Process here. And so he's kind of a mixture of, like, a context engineer and a product engine. So we threw it on to shit in there, so that's too much stuff. But if you look at a regular interview, This is not coding. Coding. Coding. Not coding. I don't know. What this is. Nish came in. Yeah. Not coding. Coding. Coding. Knockoing. So this is also Rory came in last week. We actually ended up finding this person. Coding. Non coding. And then we skipped a bunch of stuff, I guess. I'm not sure what happened. Here. Yeah, he did really well. On like one of them with. Whoa, I think it was. So we skipped one. Of those kept on. Okay? And then for product engineers, yeah, there's usually a full stack app where again, you get to use AI. This whole, like, you can use AI stuff is always there, which is with, can you build something in like 40, 45 minutes a day? And then they should say database design problem. And then. Debugging problem, which is my favorite problem. It's a nightmare. Which one is the debugging. What's it called? Prefect Debugging factors. You? Very simple. There's like 30 lines of code. There's an issue with it. And you have to find the issue. And it actually has driven people slowly insane. More like 15 years. It actually is a very, very difficult problem. But it looks very simple. It looks like way too easy. But it's just my favorite part of it. It's actually nightmare. It's actually that you tell them, like, what it's supposed to be doing. Yeah. I mean, it's clear you know what it's doing. It's reading a table and getting the first row from it. It's like the part of prefect that's so frustrating about it is that. All the code looks correct, and it's doing the simplest in the world, which is like, go to a table, get one row. That's all it's doing. But as it so the code, it looks like this. Go to a table, get one row. Succeeds, then just it does it again. Go to a table, get one row. The second time, it crashes in a way that, like, no one understands. And you can't use, like, Devin or one of these. You can use all the tools. Is there a way to do that? Or do you really just have to know how to. Like you have logic. Nowadays, GPT5 can solve it, which is kind of annoying. So now we. So we tell people this. So we say, look, it's not fun. So we'll give you Cloud 3.5. But which is kind of annoying. But either way, like, you know, you see that error message, and error message is like Async event loop broke in, like, what the. It's. It's some. And the error message is literally, like, this long. It's not even like it's actually funny. And people every time I go. I thought this was gonna be easy. So we do prefect. And it's also a moment where we start to see people lie or say, I don't know. So, for example, they're like, oh, yeah, like, I know an event, Lucas. And they see some stuff from, like, that stuff they have on their backup, like, or they'll read something and. You can see how their brain processes stuff. You can see if they can hold stuff in memory. So they read something, they read something else, and then they forgot the first thing they read. And so they end up stuck in the same loop, or they keep trying the same thing for 30 minutes. Like, okay. That's just like short term memory loss or something. Happening. Or you can see them getting frustrated. One person just was like, I didn't want this problem. To say that. Well, I was like, you know, one of the things we're testing is patients anyway or something. I said something like that. I care about Brandy was. Just like, this is a bad problem. This is just a bad problem. And I was like, well, what are the tens? Or chesting is like, whether or not. And he goes, how's it. Yeah, not about whether or not you solve the problem. Who gets to be solved. It's like, how you show up in it. And so. And people like, you know, I think after people, we've hired here completely bombed the interview the prefect. So it's more of like, you know. But the way they bomb it, I watch a lot. You know, humble? Are they, like, angry? You know, because that's. It's frustrating to do stuff here. And, like, how do you show up in that frustration? It's more important. Than like. And prefect isn't a fake problem. I literally my second week working here. Had this book. And it drove me insane. And it took me a week to figure out what happened. But it was hidden amongst thousands of files. And I literally just started deleting files. Folders. Just start. I ripped out everything until I had one file left, and it's still happening. And I was like, slowly trapping a mouse in a cage. Whatever. And then that's the file that we gave as an interview. That's history of Prefect. Sometimes you do this problem called matching, which is a classic. Like, small one. Actually, this is actually a good point. One of the themes about interviews that we do here. Earlier when we're talking, I was saying, like, AI is great if it knows context, right? Like, I think about so much work is like, if you have the context, AI can do it perfectly. We just need to know what you're trying to do and why you're trying to do it. And what ends up happening oftentimes in startups or anywhere else, is that you don't have perfect context. You have to go collect context. Right? No one's gonna come to you and give you a PRD or like, an entire document that says, like this. Do this. Exactly. You have to go and discover stuff. You have to ask questions. And you have to think about ideas. And whatever. And so all of our interviews have one missing context. So you cannot solve it without talking to us. That's why when, even when you dump it to AI, it does, it can't give you the right answer because it's missing some crucial context. For the problem. Matching, for example, everyone dumps at AI. AI generates code. It does not work. Because it's missing a very piece of crucial piece of context that only applies to accounting. And so you will not be able to do the problem unless you ask us questions. So, like, even though we've written out, like, what the problem is, we were only written out of, like, 80% of what, 20% that's missing. And what's in our head, which is what actual problems in real life look like. You have to gather information. And that's also true for Prefect. Prefect, I have a bunch of questions you can ask us. That's why you say, ask us questions. And so when someone sits there silently for an hour and does. Not say a word. I go, that's a no for me. Because that's how I think they'll show up and work. I say? He's asking questions. Like, that's collaborative. And so I think matching prefect. Notes. I think they all have missing. Context. So you need to talk, you need to ask questions. There's also, like, not a correct answer as much as you build something in relation to what people are looking for you to build. So if you don't ask questions, So what you'll end up noticing is that people who are amazing engineers, they spend, like, 40 minutes asking questions sometimes. Don't even touch a line of code. And then. And then after they've answered all their questions, you could then do the transcript. Then you can literally take the transcript of the 40 minutes and they can just recite it for three. You know, whatever. Three minutes of, like, what they just learned and AI with auto one shot it, right? We've actually had PMS do matching. Where literally, they will talk about it for 30 minutes. 40 minutes. And then I just said, at the end of the at the end of 30 minutes, I said, okay, why don't you just go type out, or you can whisper everything you've learned in the last 30 minutes. Let's see if AI can one chart, you know, and then AI does it. And so that's how PMs gonna end up writing code. So that's what we end up testing. So I don't know if any. I don't know where I'm going with any of this. I'm just bored. This is all super Opal. Let me out. So, in terms of the Atlas interview, like, loop, is it this right here that we're looking at or. That's a good question. I don't know. Do you want to see Johansey or who would be? Well, Jon was a pm. You can check Ishaan. He's an outlet Spanish or do you want like Atlas Pm? Well, you shower perfect. We haven't done enough. Okay, so this will be the first. Yeah, we're gonna define it. Okay, great. I mean, if you think about it, What atlas? You know? It is kind of interesting. We might have to come up with new interview questions. That'll be fun. We haven't come up with a new interview question in, like, a year. Okay. And so they're all kind of old now. But I think we might have to come up with new interview questions. Because I'm trying to think of any of these mean anything. I mean, look, Neil, some of this will teach if they can code and debug. But it's a lot of systems. Thinking systems building. Right, so there's a little more conceptual. I think. Yeah, there's that piece and then there's the, like, customer. Like, a lot of this, I think, is going into, and you can correct me if you said differently, but, like, going into the DI team, going to the entertainment and just, like, being able to talk with them and, like, get their problems from them. Yeah, I agree, which may be a part of this. Gets that, but I'm not sure. I'm not intellisure. Honestly. Your facilitating is tomorrow. What's that? Is that the interview you're facilitating is tomorrow? I am supposed to contribute in some way, but I don't know how yet. So I'm hoping to. Yeah, hopefully figure that out. It's kind of interesting. Like I. And then I'll get one more piece that. I'm just curious if you have baked in here as well. Is the scrappiness aspect. That was, like, highly, I guess, like, you know, mentioned by Mitch. Is just like agency is related to that, but, you know. Yeah, yeah, yeah. You don't need to be as strong as an agency, probably. Yeah, yeah. I spoke to you for Atlas. I think for newer teams, especially, like, you can't have thinkers. You just need to go do a bunch of. Skins. You have to test anything for, like, agent design. Anything like that within nanos. Designing music agents. It is basically. Like, you know, we think designing agent now is just prompts. Like there are no multi agents. It could be car dealership. Yeah, I think we need to Cardinalship 1 2. I think they might have done one already. And then definitely writing. I'm trying to think about a way I want to conceptual problem. Like, you know all those things we talked about there? Yeah. Like, it's like, how would you come up with the rules of a coding system or something? Like, how would you go about. Coming up, the rules of a court system. Or like, if you were to write a PRD template. You know, how would you go about writing a PRD tablet or, like, what would the mechanism be or something like that? Generally, though I will say this like except for airport. Every interview question we ask is something we've done at the office. And so I was a little tricky because we haven't done anything. But I'm saying you could mine the things we're about to do for interview questions and just sort of. And you can also use it. I mean, this is. Some people say it's not. I think it's kind of fun. But you can use that as a way to get ideas. If someone says like you asked someone, the question goes, that's not bad idea. But yeah. I. I'm just trying to think of, like, what interview questions would be because I almost want them to like, yes, they have to be override problems. Yes, they should be able to write code, like decent code. I think matching would be matching not that hard. Cool tomorrow for Atlas. Yeah. Oh, he did manage. Okay, this agenda. Okay. Really push them now to lock in on that. Let's do it. I like that idea. So I think you did notching an airport, and I don't think he did car dealership yet. So I think he should do car one and two. One coding thing. And one system design. Maybe this is like focusing too much on the candidate tomorrow. But he, I think. Really bombed coding. Connor said it was a fantastic first half and he didn't use AI at all in the second half. And it's very poor jobs. I don't know if you want to try and assess that at all. Go heavier on the coating than normal. Then you might normally. Oh, we do have that merge. Kvo on a home API challenge. Than you did. Well, we did. Sorry. We did the coding so we don't have to do that, per se. Magic we've done. We've done matching. We haven't done car deal, ship. So 1 and 2. Then. We'll do. The ball match. Ing. He did very well in the first half, which is like breaking down the problem. And then he didn't use any AI on the second half. That did very poorly. Well, he's an fde. This is like fdas are like good egypt. Okay? Yeah, this is. So then it's like more. I kind of think that if this is also where we get interesting, where, like we don't have a general process for one hour interview questions and to our interview process, partly because we customize it, it's not scalable, obviously. But we do customize it a lot to the person. In this case, for example, like, if his coding skill is fine, then from the. Maybe I'll start with the framework, which is like, you know, we're gonna do detective work. We've done some detective work already. Which is that you know he knows how to code. He's past some cultural element, which we can ask mentioned as where I go to Machango. What are your cultural concerns? And he can tell you some of them. And then. And then we imagine he needs to write prompts. We need to see his writing skills. So car dealership on Car Dealership 2 as a functionality, that's just part of the job. And then I think it's a lot about collaboration stuff, and I do want to stress them out. You know, somewhat. And then see how we like. I like to fight in interviews. Or like. Like argue in interviews just to see how they argue back. I don't like to fight. I'll never forget walking past and the guy was like, it. Just pulling his. That was informed. That wasn't on me. I literally came into that room and he was already doing that. That's just him. Who was that? I can't remember. Anyway, we didn't hire. Listen. No. If he would accepted it. Eris was really stressed. You said told I was to give him a really hard time. And he came out there. He stressed. He's like. He told me to give Martin. I don't know what to do. No, that. Was on me. I should not have had that. One is on me. One guy was just kind of annoying me, and I was like, Came out and he went to go get a beer. Iris is happy, though. He's like, oh, my God, I annoyed him so much. Okay? I think I'm trying to think about what? We haven't done airport with him. Haven't we? I did. Airport him. How do you do? Nikki did well on that. Did you like him? I liked him. I know I liked him. I think I. Plus, we're hiring us. Did you like him? Yeah. Did a good job. Got a good sense of how he reacted. He gets stuck. He, like, panicked and blinded. And kept going back to use A preferences, but I was eventually going to push. Him, like, push him out of that. I like that he, like, pushes back when he's confused. And he, like, brings his own solid ideas. He's very excited for Atlas. And like, yeah. Prospect is something he can build on the scale. One and two in writing. You filled in power. We do play back for a. Do you want to do some, like, actual Kuhne, like, build matching in the actual color? Nobody bombed the coding session. He did. Yes, I just told you. Oh, boy. Sorry. Holy on the second half. Oh, he's AI. Yeah. Oh, then we have to test his car. Yeah, yeah, totally under. No, it's our prefect. No. We're given his background, we can do Ulbert. Yeah. I think we will only get us personality gate. He will not be able to do any of it, technically. And that is okay. Now let's do cooperate. Then Clovers are pretty good one. Hour. What is Culver testing exactly. So Kohburt's interesting in that, like. It was originally made for, like, a machine learning engineer, specifically. But with. With AI now, like, it's now becoming about, like, do you kind of get what's happening? Like with LLMs and AI. Like, can you build a system using alons in AI? You know, and so. The, the question is, it's a very simple thing. There's this thing called cover, and there's this, I'm gonna go really high level, and it's an option against using OpenAI. And so question is, very high level, should we use covert or should we use OpenAI? And you can code up. And so we have, like, a loose plan as to how we would go about doing that. And do anything you want there, but we have a loose plan. Which is essentially, and we say, can you call it a solution that tells you whether or not issuance cover up the island. But we give them a lot of code, a sample code. So it's more like fill in the blanks. Once you get what you're trying to build. More than it is. Like, we already have, like, a fine tuner in there and all this other crazy stuff. So, like, you don't have to write, like, crazy code. The whole thing is going to be, like, 20 lines of code. Like, inspecting the output to figure out. Yeah, and there's a little bit of like. Yeah, that's a good point, actually. That actually makes sense here, too. Which is like. So the. The whole thing is you have a lease document. And you're gonna build an AI system that when you ask it a question like, hey, how long is my lease? It'll tell you the paragraph that has the answer. It'll just show you the paragraph that has the answer. It's not gonna tell you the answer, but I'll say this paragraph. Has the answer. And so you can just OpenAI the builder, you can use Kulburg to build it. And then you compare each of them. But the document itself at least aren't like any other document, actually have a lot of issues in it. So, like, for example, most of the document is the word page break, because every page. It has a page break. And so if you don't literally read the document, And, like, see that it has the word page break everywhere. Then, like, your code will incorrectly say that one of the other one is better because it's just predicting page breaks. And so you have to, like. You have to go check, like, this whole thing where people are like, I'm dumb, like, okay. And just go, like, how do you know that you're right? And that's actually a very hard thing. You can say something that says, culver's better or OpenAI is better, whatever, but then I go, like, how do you know that you are right in saying that? And then you see them bumble again. So there's. There's not a confidence in it. And so you have to go read the doctrines and go. I actually like Colbert for this. That sounds like an eval's thing. It is a little bit of Bevos, but it's manual, you know, it's. Not like, millions of files and things. One lease document. Right. And so you can literally. Just read it. And so the best people, for example, will open the document, read it. I'll go, oh, there's issues here. Okay, I'm gonna go write some code to clean that up first. Okay. Now I'll be able to clean document that's not a dirty document. Now we have a clean doctor I'M gonna go write some simple. And the voltage is like 20 times. But it's like a little bit of that. It's like checking. We also check around the stuff. Like, did you check along the way? Some people write all the code, and I can see an issue in, like, line 10, right? But they're like, oh, I'm done. I'm like, are you sure? And I'm like, yeah, I'm pretty sure. I'm like, I see an issue. In the code or I see a bug in the code. And so you end up anyways. You see a lot of stuff even in the 20 lights goes like this. That makes sense in terms of customizing for him. My like one reading just a resume. Is he doesn't seem like he's worked in, like, startups before. And so again, back to agency would be like the one. Do we have anything to just test? Are they the type of person that is going to actually develop things for the customer rather than for their boss or whatever, you know? The symptoms I will do. I think this is probably sussed us out. This is one of those questions. The other part of our review process is like a good point, which is that we all share notes in a way that fills out what you don't have to cover something that someone else is covered. So if Mitch comes and says I know has ignored. Got it. You don't have to worry about that. FDE is a talent chair specifically. Usually I have higher agency than not. They're sent it to. They don't work for Palantir. I mean, they work for Dr. But they go out to their customers. Part of these smaller teams and they are more high agency people, they're actually shittier engineers, honestly, than they are. Sometimes. But yeah. So that's. That's for him. I'm not as worried about agency, and I think Mitch is decently good at sussing it out. The only other thing I'll say with him, actually. This is actually a good concern. Which is. 22, 23. Yeah, he's young. So the issue with young is often you have to manage them actively because they need to be trained in certain ways. And so either they have to be really. Not even hide anything. Like, they have to be really amazing self teachers. Otherwise they'll go fast and build a bunch of garbage. Which will kind of work, but then kind of break 90% of the time. And so they don't have, like, good system thinking. And they don't probably usually especially down to they're not necessarily great mentorship. And so from a coding perspective, I'd like to just see how good is code is just in cleanliness wise and all that stuff. Because if you can't do that, then he'll build suffering quickly, but it'll be like it'll fall apart very quickly and so then, then you won't actually be able to stable system. So can you build a stable system would actually get concerned. Given it's just age and a lot of folks. I'd be surprised if you can. And then you take a trade, and she's like, oh, who's gonna teach him how to code? I'm like, will he listen to that person? Like, this is where the wants to learn that. It's like he would need someone on the engineering team who, like, make sure his code makes sense. And he's being taught. How to code properly. Which I don't think he's ever probably been taught. Internships, they never teach you that. Really? And Palantir doesn't have a great mentorship skill unless someone really takes interest in you. And so my guess would be that he's self taught. And so is he open to mentorship? He's open to that. And then two, who on our side is gonna literally do that and take the time to do that unless that structure. We have to solve that problem anyways, given that we have more folks coming in. So that's probably we're happy to take on, but just something that I'd also keep in mind. Understood. Also Simon. I think he's 24, 25. You always go very young in this candidates. Oh, I graduated. Sorry, you graduated? Buried up. I graduated. My mouth is so off. I graduated when I was 20, so my math applied. Graduation is off. 23. Oh, yeah. He's 22, 24, 20 times. Two years ago. Yeah. Or you can say two years ago. I was about age too, as she just experienced. I'm not promoting stage, but I am holding surprises. But yeah, two years founder. Yeah, it depends on. Your funds. On them. That was the computer. I think one system design and two, I think you should definitely do a one on one with everything. Okay. Or maybe we should do. Because you haven't done anything. Maybe a two on one or something. Just so that. Just to see how you guys worry about it. I love someone that engine to get to know them as well. Because you have to find their mental for them. Yeah. Do you want to do it? Okay, you guys, we're too warm up. Okay. Fantastic. I'll have a step in for car dealership. Yeah. For that. Two on one. Do we have a typical way we go about it or just okay, we can go after it, Okay? Great. Shadow. Yeah, happy to have you on it. I'm trying to make it look not just cool. Aren't you shadowing tonight? Or am I? Oh, wait, the mini comic. Come to a movie. Sorry. Give me crash. I really. Okay? Yes. I'll put you on for both. If you don't want to do too. You guys are still a little short. Maybe not. Actually. You should take Ilio up for tomorrow. It's still in the interview. Says to be her scheduled. Yeah, he's stuck in Canada. I'm just gonna leave it for the moment. Everyone knows he's not. Okay? Wait. What happened? Ilya's not coming. Stuck in Canada, so he's gonna reschedule. Is he still selling his company? Or because of, like, visas. I have feelings. Visa stuff, but who knows? Oh, he's canadian. Yeah, but that shouldn't be a big. Business with holding him there. Maybe. I don't know. I'm sure he's either he has stuff going on. I have two. No one sells a company fast. 2:1 slides next week. So brian canning and. Neither one. I want to be more helpful in this, but I think the first. This first time around, just like getting a Santa, you guys doing probably the best way to be helpful for the next one. It's a very highlight. Good. Yeah. No, this is very thoughtful for sure. I think that in the 201 again. Actually. Neville. I don't think two on ones work. Well, should we just do? We've never done a lot of. What? Should we just do two one ones? I don't think 200 ones work. It's like two people. I don't play on the house. Trying to establish a personal connection. Again. I agree with you. Yeah, I think for training. Okay? Yeah. As long as I'll be quiet. All those languages, two on one. It's just ones people talking. I think it takes the pressure off of the. We have to get. To know, test them or whatever. If the two of you guys show up as, like. Hey, I'm just trying to get. No, we're here for 30 minutes. Who are you? I really started talking to someone. In an hour long interview. We spoke for 30 minutes. And at some point I went, wait, no. I'm so sorry. Who are you? Know, just get into a conversation. It'll be authentic. Because I'm still learning who Ashley is. Is she still learning who I am? Yeah, exactly. We're all learning. Actually, honestly, I would bring that up to start and then it also break the ice because. Anyways. That's up to you guys. I have to run to another video. Anything else. Was it helpful? So I came into learning. Every session was. I've got two of those. I think I'm bother more did the other one Ashley? Oh, yeah. Bother Ashley. The world was gonna. When we talk about revamping the system. We'll highlight what each section is. Assessing forward and how we're assessing, and then that will have more. I just wanted to get a little bit detail and just in terms of two Ashley, design the next set of product engineer interview questions. Should we, like, is that. Do we do that, like, next week or what? Yeah. That's a good question. Why don't you join our we're gonna do. I don't know. We have victory. Yeah. I think ours is a bit more process related. It's not gonna be. Yeah, the actual engine. Well, I do wanna. I do want to have the squad and all that stuff. Okay, so I kick off. Yeah. It's quad kickoff. And so. And then interview questions, I think is a topic in there. Alongside, on slightly alongside. A bunch of. I think we should just, like, lay out all the open we should do the same thing, lay out all the open questions. Then start to answer them. Kind of thing. And then do it weekly, check in on it. We don't know, but we will add you. Okay? Okay. Understood. Sounds good. Yes. I know. The on site. I have one spot. Or we can do tomorrow. Six fifteen works. Let's do it. Okay. Yeah, that's great. This isn't timely. Bad. Can I grab some time with you too? To just go over the sessions? That we can cover. I'm really excited for this. And then for the recruiting. Obstacles. We have a lot of process. Amazing. How do you approach experience? It's funny. I did a bunch of interviews from our last company. Since High Cove Hunter and I were the ones that had to come with the whole process. And I don't think. I don't, like, I don't love it, like, so I'm, like, trying to take in as much as you guys did it here. I can't say that was, like, the thing that we mastered. Some things did very well. Interviewing maybe not as much. But I would tell you, some of the things maybe I agreed with was, like, we always tried to do it very casually. Like we wanted it to be more conversation than, like, a test, you know? But yeah. No master. Master plan. I also. Did tomorrow. 