## Meeting
Calendar Event Title: Eng interview training: selling
Calendar Event Time: 2025-09-15T18:30:00-04:00
Meeting Note Title:Eng interview training: selling
Attendees: Guozhen La,Neville Jos,Connor Mann,Ryan Moffat,Chelse,Boyce Young,Ashley Wong,Eros Wang
Link: https://notes.granola.ai/d/64bca278-5a63-48b5-8107-a8bdc1e0c6f1

## Transcript
 
Me: Trap here forever. 15 101. Is there a world where it possible. I'm trying to think if that's true. I don't accept that. I don't like that. And I don't want that. All right. What was my introduction? They don't even care. It's crazy. Power was the worst you were thinking about. Chill. I don't know if they're. I mean, that does capture what I'm getting it. I don't know what it is. Okay, who was cool? I think. Wolves on vacation. She's on vacation. Ready. I thought it was. Early. Okay, great. Anyone else. This is it. Okay, welcome. To want to take this because there's been a few pieces of feedback. That we've had. We're trying to get better at the recruitment. Sorry. I just realized I had coffee. I have a lot of energy. We're trying to make the recruiting process. Better. And part of that recruiting process is the fact that we talk to candidates at different stages. At different times. And as a candidate. As all of you guys have been told, this process. You're on the thread you're always trying to gauge, right? What are these people? Do I want to work there? And Charlie seems to collect that information. And so as we scale up our recruiting processes, engineering process. And me. Matt, Mitch are not the only people targeting candidates. Over time, all of you guys will eventually be talking to candidates. Learning how to share what basis is truly like the way we work, the way we think, the way, whatever. There's nothing. There's a way to do it. But it is important skill to practice in order to continuously kind of relate the message. To candidates that this is a different opportunity. That is a different place. That they should relate to this one over other ones. That they have, Especially if they're good, they'll have options. And things like that. If you want. I don't know if you'll be selling. The recruiting. Maybe. Okay. Actually, no. I wanted to take this just for engineering purposes, because there's only a lot of engineering questions. It's mostly an engineering focused one. They're doing more. He's an engineer. What's his role? Is he doing lots? No, he's a recruiter. Okay, then let's get Chelina. Here. I'll be right back. So what I decided to do. I brought sample questions that people have asked in their case and fireplace. And then. We'll ask the question. Like the audio. And then we can play with how to answer it. In a way that. Might be. Should randomly choose someone to answer the question. Do you want to do that? I thought about this for a second. I think we have immediately. We should definitely, definitely do this. Pick anyone, but. Yeah, actually, every question that Ryan has, you should probably pick him. Though. I feel like I had the most different 3D process. Ryan, remember when we did coding in my interview? Like, literally not. Oh, I remember this. Is one of those processes where it's, like, legal. All right. Okay. We have arrived. All right. Hi. So, Jessica, contact sharing Engineering team is working on trying to make a recruiting process better. One of the things we're doing is just. Learning how to talk to candidates. In ways that make basis and exciting prospect. And so I just did. Look, boys, a little bit. As this practice, just to see if this makes sense. So I want to give up some sample questions. That we'll have asked during it. Remember, it's an interview. And someone can ask anything. And people have asked everything. Anything and everything you think about. And having members a few hundred times. You kind of get used to. The kinds of things that might ask, okay? So I don't know which one's the easier. One or hard. Easy. Easy. This is maybe one. I like the one that I did with. Okay, so this is the question. I feel like a pretty naive question. Of. How do you combat hallucinations? Is it like, how many deterministic rules you run? Or do you run like LLM as a judge? What kind of things we have in production. To reduce hallucination. Okay? What? Someone asked that in an interview that's asked about, like, 20% of their time. I guess that makes sense in your interview. So someone asked, like, how do you reduce hallucinations? This is more ML Focus Canada, but I've had product engineers ask this question too. Boyce. You're on a lot of dances. Because we just talked about this for a bit. Okay? Who wants to try to answer that question? Okay, I will. Can I just answer this? As in, like, I'm just, like, trying. Okay. I'm not thinking about any sort of. Okay, no, think about it. The whole point is to think about. From my perspective, when I hear hallucination, what I think is someone who's a chatgpt and they ask it for a fact and it makes something up. And that is definitely, I think, what most people view as a hallucination. But, like, in reality, I think what people actually mean is the agent just gets something wrong. And so it could be that it just made up something, or it could be that it added two numbers that really did exist incorrectly. And so in my mind, this question is just asking, well, how do you make sure your agent is reliable and answers questions with as many nines as possible? And the answer is that you do a lot of testing and you look at the outputs. But they are stochastic. So somebody said, ryan, how do you guys go about producing hallucinations? In production. Application. What would you want to say then? Please. Your what station between this. And the previous question. No, you can say whatever you just said. I think they would leave the whole pipeline. Wait, what do you want? Yeah, wait. Okay. Okay. Well, okay. I'll give you feedback on that. First of all, you started off by saying what you're asking isn't even what you think you're asking. I see. Right. Which isn't an invitational energy, right? We're looking to collaborate with someone. We're looking to answer their questions in a way that's not like you're not even asking the right question, actually. Which has an energy to it. What do you consider to be hallucinations? Like, could you define hallucinations for me? Okay. I don't know. Things go wrong sometimes. Okay. Is there a difference between a questioning. They're asking you a question. Don't reverse interrogate them back. Okay. I would just get the initial diatribe hallucination. It just goes to. And then I would just go into. Well, you're kind of just asking about making them reliable, so, you know, testing. Okay. Testing. Great. How do you guys test? Well, it depends on exactly what we want the Asian to do. But in general, because we have LLMs do a lot of different things at different points in our code base. So in each case we often start with like a handful of common flows and ways in which we think the user is going to use them. We set up what are kind of like end to end tests where we have some like input document and then the data that we think is correct and we verify this for their in house accountants. And then we set up some sort of automated framework to just test and verify. And yes, in some cases, we do use elements as a judge. If it's like a fuzzy string matching. Other things you convert programmatically. Great. Now that's a decent answer. Now, the question is, how is that answer different than any other company? Every single person will ask a question to will say that exact sentence. Right. How do we stand apart in that? And every question has this trap. And in every single question they'll ask you, they're gonna ask someone else. Right. That's the nature of their questions. They probably have a predefined list or some type of questions they're kind of thinking about. And so there's this weird thing where it's like, if you give a good answer, So what everyone else? How much would this value eating that you need ness of the answer versus just like, are you confident and you can give me the correct answer? Because if I ask someone a question and then they just make up some, like, dumb, you know, bullshit, which is completely wrong, and then I'm like, okay, I don't want to work here. You don't know what you're doing. No, I agree with that, But I'm saying, assuming that, you know, they're working with companies that have competence. Like how many people doing copy and things. Why is she asking it? What does this matter? To her. Like, in an interview, you get, like, big questions. Let's just say she chose this as one of her questions. Maybe there's something she's trying. To struggle. True. Why would that matter? Maybe she wanted to work at someplace. To have some insight or knowledge. That she doesn't have. Okay, that could be true. Yeah. Chose this. I'm not saying I know why she chose this. But there is something interesting about the reason she chose this. We can make up whatever reason it is. But what else do you think it is? Could be that she has experienced with this. Or she wants to know that I actually had an interview today with someone who works on AI agents in controllers space. And he talked about how he builds agents. At their space. And so in relation to that, we talked about how we build agents. In very different. And he's like, oh, you guys are doing it, like, in a way that I never thought about. That's exciting. Yes, there is an element of that. I don't think that's what happened in this case. Because she comes from an ML background. Not even that much have a Lux. So she's never actually really worked with LLMs. But more kind of buying infrastructure. So she does. She doesn't have the work experience for that. That's just context. I have. What would happen if hallucinations happen to the product? Be bad. And so one way you can say this. Is saying, she's saying. If you're using LLMs, she doesn't know. LLMs can be wrong. Is your product any good? It's how I interpreted that question. I think that's correct. Right, but my interpretation of that question, the moment she said it. Isn't about hallucinations. Is it? Do you have a good product? And how could you have a good product? If the thing you're building on top of can hallucinate. Because if we don't have a good product, that people don't want our product, which means the company is not very viable, which means you shouldn't join it. Because why would you join a private company that doesn't have property anyone wants to use that's unreliable? You want to know at some level. That the thing you're going to join has something that people actually care about. So if you have that. Framing, which I'm just making up, wanting the truth. But the moment I heard that question, I went there. How would you want to answer that? Now the question is really, like, is your product any better? Lms have blue stations. Which create incorrect answers much in the same way that bugs also creating correct answers. And so I think at the end of day, this is just a question of robustness. And accuracy. It's like even if we weren't using lms, we could still get incorrect answers through normal programmatic bugs. So is your product terrible. Let me pull up these financial. Anyone else? Take a crack at it now that the question's a little framed, a little differently. If someone just said to you, like, hey, do you have a good product? How would you say that? How would you know? If they asked me that. Hallucination? Yeah. Well, this question. I actually interpreted it a bit differently. I guess I got too caught up on the rules thing, which is like, you guys just write a bunch of rules. I would go straight for the systems on. So we're not writing a bunch of ad hoc rules or return builders. That's a good one. Yeah, I like that. Shows a philosophy. We're not doing a bunch of random stuff. I think that one of the things I was talking to Voice was. And I realized as I was saying, why are we answering questions? What are we trying to do here? Had some level there, trying to gauge if this is a viable company they should join. And we're trying to gauge if they're a viable person we want them to really want them to. Do part of us. At some level. So questions and answers are masking this thing. If someone says, oh, what model do you use? What does that have to do with. Do you want to join this company? Do I want to join this company? Right. It becomes somewhat twisted way in my opinion. To gather information. But if you're just more directly answering the question that they really care about answering, Is this a good place to work at? I just try to often answer that question independent of the independent one they ask a little bit. Like she's asking is your product. Any good. When do we start building evaluative course? Like real good evals that avoided hallucinations. Eros. Something that beginning of this year, maybe beginning this year. Even the robust. If you think about tasks, how much evalu do we have on task before we release? Exactly right. But a lot of e cos on tasks. I mean, we have accountants. Using it. But we didn't have e val data sets over tasks. Well, we did on this specific ring to Ohm skill. Because everything else is determined. I agree with that. Okay, so we both data set, Yeah. On that. And did we get rid of all hallucinations? The program really isn't hallucinations. Well, do we still make mistakes? Give mistakes for sure, okay? So is there product any good? Ok. Why is it still good if it can make mistakes? It makes less mistakes than a human. Is that true? Do you know them? Humans take a lot of shit. Just point at the person. You just have to be more efficient than a human. I think the mistake is oftentimes the context show. I think the nature of it is that there's a lot of ambiguity. So mistakes happens when things are not defined. Very clearly. I completely agree with that. How do we deal with mistakes? Like the product makes a mistake. What do we do? A week in it or insure. What kind of customer? Do. You expect to comply to it? Yeah. I 'll hold. Product is built around auditability. Because our customer is going to get older, they get all this. So every step of the way, we generate collaterals so you can see what went wrong and what we were looking at and then how you can fix it. You've heard me say that original thought. So in this question, I'll just use a sample question because I think it's kind of a fun question. Like she's saying, What does she say again? How do you combat hallucination? What I heard, which is, like, is your product. Any good. Or like, how function? How do you build a hallucination? And so my answer in a lot of ways is not about hallucinations, because hallucinations happen. So many AI companies are trying to avoid hallucinations. They're trying to go for perfection. What if we just say they happen? That's just a part of life. People make mistakes and make mistakes. Then we focus on the product elements. To make sure that mistakes can be worked with either you understand what that mistake came from? You can give feedback to it. We have mechanisms for feedback. Mechanisms? We have mechanisms for seeing traceability. And so mistake. If someone just came to you and said, hey, you have to pay 17,000 for the taxes. You're like, why? And then they left. That'd be kind of a bad outcome. But if they said, here's an Excel file, here's all these entries, Those add up to 17,000. Or here's all these other files we found. That's why we think this. We have some level of traceability. If you would say back, hey, no, actually, Can you ignore these specific transactions because they don't actually matter, and then rework itself and then. Got you the correct answer? Sent 10,000. Whatever it is. Then you rectify the mistake. And to your point, I think I was a little bit like, it's contextual, right? So you need product experiences through which you can collect more context. So that you can fix your mistakes. Sometimes it's just a pure hallucination. Runtime stuff, but even then you get the raw Excel file, so you get some numbers. You understand where the map went wrong or whatever that will make a mistake. But you actually have the files so you can do it yourself. Even if they allow them made a mistake. Right. And so my answer to her is that hallucinations are only. Are not a problem we're gonna solve. Doesn't actually matter. Yes, we're gonna believe our sets are trying to get better, but at some level, we also have to just assume that they're gonna make mistakes and build beautiful product experiences. That customers can work with those mistakes. So when we end up focusing on those problems, we get to be earlier. In the world of AI Companies because mostly AI companies are still waiting for hallucinations to go down. While we work with hallucinations and build product experiences to account for that. That's why we got there before everyone else. We don't have to wait until they add and get smarter. Right. Like that pitch now makes us look, which is actually what we do. I might keep making that up. That's actually something we focus on in the product experiences down and actually put a lot of effort into that. Into that thought process. Now, maybe some of you guys know gas, but didn't. It's fine. But I think that's where we say this is what basis believes. Spaces believe that product experiences are the way to combat hallucinations. Our practitioners matter in general. Not just really rely on AI. And so that's how we would say. Slightly different. That makes sense. I think it's hurt. Like hearing a question out of the context of the conversation makes it difficult to. The question before that, I think would inform a lot of maybe where the person's head is at. No, it came out of nowhere. Okay. So in this case, literally right before that, she has a completely different question. That's right. And then she was like, yeah. This is how questions. Do you think she had a list, or do you think she just, like, right off the dome? I don't know. I think the question before that, which I ended up. This one's like an ease, this one's a more upgrade. Opaque one. This one's maybe. I'd actually like to see what you guys think of. These are harder on whatnot. You're not. Oh, yes. Are you disconnected by? I am connected. Mine's fine. I have two bars. Not three. Those are crazy. Cool. Let me turn it off. Turn it back on. I feel like the question makes sense to me. Like for Anyone who uses ChatGPT casually or just googles all the time. They always be careful if they be wrong. Everywhere. That's just like, if you read any of the text around, any response you ever get. Always just be aware. We have no idea what we're saying. No. Exactly. Concern for someone joining a company's bill using this technology. Yeah. Whether or not she technically used the correct term. And the correct context or whatever. Guys were just like, oh, but that's not the right way to think about it. So, like I do think there is something useful. In some of our experts during how they think about it. Yeah. Nicely. Yes, some information about this is how we think about it. And this is or isn't our biggest concern. But here's, you know, where we focus our intention. It's nice. Even if it doesn't, like, directly turn into a cell. Because she may not know that much. Yeah, I don't think she knew that much anyways. And that's the other part of this, which is. I think she probably didn't mean it as, like, an aggressive product. Sucks. She probably also opening. No, I didn't mean Potter. No, I'm more like, do you have a product that people actually like and use and it's reliable? Do you have a product that's reliable? That's a good question to ask. A lot of startup products aren't reliable. And so they try to build businesses and develop that, and then they fail, because a lot of times, very good. And if you believe in things, phrase that. So, you know, I. It's good for candidate students make sure that the broader is a good product. The question. She asked that before. That was a different question. But what is the most difficult problem that you have to most technically challenging things that you work on? Hallucinations. Okay. You want to take a crack of that one? I don't know. What's the most difficult problem you worked on? Say what I mean, not what I said. I just, like, one of the big, like, risk that you see right now. Right now, Brandon doing, like, risks. Not risks, but maybe challenges like that you're trying to cover as best as a heavily as possible right now. Yeah. Who is that? Josh? I didn't think. I like. I didn't like. What's the question? Okay. So I said, hey, do you have any questions? I think I still wanted before that. No. I said, what can answer for you? Sorry. Your baby just showed this in the track. Do you think it's worth when kind of using that, like, tactic of kind of drawing extracting out what you think they're asking? I guess there. There's. There, 's like, obviously the risk that you misinterpret and you actually just answer something that they did not care about. Yeah. Is do you think a good way to hedge that risk is basically to, like, allude to a direct answer, but, like, then kind of explicitly say, I'm assuming that you ask that because you care about this, and then answer what you think they're. Well, I always. I always use the thing they're asking. About. I never don't say it. So I don't. I say the word hallucination a lot. But I'm saying the thing that I'm saying. Yeah. You know, but I'll say like, something like, you know, hallucinations are really important problems because I'll say something like, product quality managers a lot. Like we want to deliver a product experience for customers that really. And I can. So I, I end up moving the conversation, product quality from hallucinations. You know, hallucinations are a problem. You know, But I can say, like, hallucinations can be a problem. Yeah. If you think your product is fully reliant only on AI being 100% correct. Which, if it never will be, then what do you end up doing? What do you have to do? And so waiting for AM and then you can just talk about and then you just switch gears a little bit from there. Ok. I mean, this is maybe a personal belief. I kind of think that. It's just like, you know how we're a first principle believer, so everyone works in. So one of my. It's like every candidate is only asking a few types of questions. Really? Like every question is derived some from some key set of things. Are you good at people? Is this work interesting? Will this business survive? The next two, three years. You know, I don't even know if there's that many more than that. At some level. You know, does this. Oh, will this align with my personal professional goals? You know, which are different sometimes, if you want to be a singer. There's like, people have personal goals. And, like, their questions are like, does this get me to where I want to go? Which has something with the company or the product or any of that. Stuff. You know, So I usually think of it as, like, four to five different questions that they're really asking through the form of, like, these 10,000 questions. And so, you know, and, and so I can understand the, like, very natural instinct to be like someone. That's where the listeners. Right. Like when you're testing such a. But that didn't answer the question. They. The reason why they asked the question. Not that I know it, but I think they have a reason. And that very specific example, because I'm not. Because I actually did a good answer on this. And I went on a whole thing about hallucinations. Anyways, and so, you know. Yeah, pause there. That was a great answer. I took my. I took my. After my, like, 17 minute rant. No, it was actually, like, two minutes. It's fine. Okay. But, like, you know, go around for, like, two minutes, and then I go. I actually fell into that one. How. Actually, I. I know when I answered a question well, which I'm nothing to do with hallucination. Okay? So all I just say, like, if maybe that's maybe a way I'm. I'm still also, I don't know how to teach this. I'm trying to figure out how to do this. But maybe you can try to think about which of those five or six questions they're really trying. To ask you. Maybe trying to take your answer in the direction of also answering that question as well. Can we listen to the Josh Burt question again? What are the big, like, risks that you see right now for engineering? Like risks? Not risks, but they maybe challenges like that you're trying to cover as fast vividly. As heavily as possible right now. So. Okay. I don't understand what the Russia's asking. They say one of the bigger French name right now, like engineering at basis or engineering as a field engineering. Should I quit engineering? Okay, so, yeah, he says, what are the biggest risk engineering right now? What's the big? People ask me this all the time, like, what do you think you have? What's on the top of your mind? Nowadays, you know? What do you think? What keeps you. What are your nightmares? Someone said something like that. Like, what do you. What keeps you up at night? I was like, keeps me up at my head. I'm fine. If you're asking for things that are, you know. So what do you want to say? I think I read that as a. I would. Okay? I think it's either a is this business going to fail Question or is there an interesting thing to work on here question. I think it's more the former. It's both kind of. Right. Like, yeah, I guess you could probably take it and maybe you can hit both at the same time. I struggle to think of a way to do that right off the top of my head. Think about it. It's kind of interesting in interviews because you have to do it that moment, which is crazy. Yeah. You know, and if you say a pre canned answer, they can feel a precann answer, which is also interesting. Right. So each time someone asks me the question, you have to, like, rediscover it. In that moment. But it's helpful to think about some frameworks. I never think about these answers ahead of time. You know? But I think I've also been at this company so long, I think about it so often that. Also, sometimes someone will ask me something. I don't know what the answer to that. And like, at least even the honesty that people actually appreciate and go, well, what comes to mind right now is. And then I just start saying whatever comes to mind. In that moment. What comes to mind. I'll take it in the first direction. I think. I think something that we're struggling with right now. That is definitely a risk is that we are, we're trying to build a lot of products at the same time, and we're trying to onboard a lot of customers very rapidly. And balancing shipping very quickly. With maintaining our product quality and not upsetting our existing customers. Is very challenging, especially with a small team. And. That's part of why we're hiring people. We need people to help us with that problem. But it's very difficult to balance that. Okay? What did other people hear? What did you feel in this response? Do you like their response? Did you not like him? I think that response is bullish. It's like, oh, we got a new bunch of new customers coming out, but we also have a version of suite of existing customers that like, both these are significant, where we have to, like, care about both of them. And we're also doing a walk right now. And, like, we have, like, thought out product things that we've been planning and are pushing. So it's like, well, you know, stuff is happening. Stuff is happening. That's true. I think something outside, maybe ADD is that we feel like we need to move very, very quickly. We think is AI gets better. Catching up to the progress we've made so far becomes easier. And we have to move fast without. Pissing off our customers. Any other feedback. Maybe it's all. Yeah. Any other feedback? I like the mention of small team. The more you go like interesting problems, high growth, small team. Says ownership. There's a lot to own. That was not a very well thought out part of that. Just threw that one in there. So I'll take no bread. That's what I'm saying. You don't have to pre plan these. Whatever comes in that moment, it's fine. You know, it's just like, I find with a lot of the stuff, it's like, holding the kind of high level of bear. I'm always trying to remember. You're trying to recruit. Right. Like not here to answer questions. Like, why are we like, you're not there? You didn't show up to this hour to answer questions. That's not the purpose of the meeting. There are meetings that are about answering questions, people questions. You answer the question. That's what the point of view is. This is specifically to recruit. And so when we're in a meeting with the person and both people agree that that's the point of the meeting, You're gonna recruit. And I'm gonna also recruit in the reverse orbits. You should work with if I wanna work with you and. So when you're holding that intention, your brain will just come up with slightly different language. And different ways, and that's where small is a good answer. Things will come up when you. My belief is like when you try to recruit. Things will come up because you're set your brain to that. Headspace. Then I'm a question answer which is the different answer. Questions. But if you're in a Q and A for a conference or something, it's a very different thing. Someone asks you the same question, you see very different things. Same question. Contextual. One thing I'll just say is tone for when you are speaking in that moment. You sounded sad. Or something. I don't know what it is. So if you say we have a lot of work. But you go, oh, yeah, we have a lot of work. Very different sentences. Right. And people are picking up because also remember that both people are in semi performance. So in every way is showing up not as themselves, but as a version of themselves that wants to get a job. So it's never meeting the real person. None of you guys. I don't think showed up in the interview. The Chevy choking office. I don't believe. At least there's always a part of it. It's like you don't know these people. Over time we get comfortable and become revert to natural self. But in the interview, it's a high stress situation. We're asking questions. You got to be on your toes. In that moment. People are hyper aware about eqs and stuff as well. And so just even in answering question the way we answer questioners want, right? Like I lean back. Or totally. If you're recruiting, there's always a ton of underlying excitement. There. Independent of the question or smile and all these things, just because we're always kind of having that helping to it. You can always answer your question. And I personally, I think my recruiting stats go down when I'm stressed at work. Just. I can feel that. When I'm talking to them, I show up to meet them, like, oh, is this guy. So miserable. I can feel that. I'm like, fuck, I like it. I actually. It's hard, but, you know. And that will happen to us. That's fine. But totally just saying that. Is the only thing I would give feedback to. Makes sense. The only thing I'll say is yeah. It's like if it's a lot, a lot, a lot. Some people might feel like they're not breathing room. Right. So some cultural elements. Talk about, like, just think about when you say a lot, what do you mean? Man. Like, if you say there's a lot of work, there's a lot of things, there's a lot of this, and you say them in total down energy. That sounds like you might be. What if I was excited? Normally I'm excited. It's kind of interesting. I think this whole thing just bring me down. It's a good question. I mean, I think there's always this element of balance, right? People want a good job that pushes them is my belief. Okay? People want anyone who to be here, they want to be in the part of the startup. They want to have interesting problems. They want to achieve a high growth target and they want to go part of the partisan scale and team and learn a lot and grow a lot and a lot, a lot, a lot. And then they're like, and also, I want to be happy. And also I want to be hate my job and be tired. And be burned down. And be sad. In it. And so personally, I'm answering questions, are trying to hold both those answers. So I'll say a lot, a lot. And then immediately go. And also there's perks. And then we constantly switch back for it. Takes only a week off. It is interesting because I'll say like real work. I sometimes say like I work 10 hour days, 12 hour days. I say that to someone also to see if they go, oh, if they go over that, then maybe it's enough. Open to nothing. Has to but open that possibility. But then I'll also say, but you can also brains or. Subcultural stuff. So just maybe I'm surprised. Makes sense. What do you guys think are the biggest risks? Anyone else. To try to be honest with this. The other part of this other part of interviewing I'll just share is honesty. I like honesty a lot of interviews. I think that's one thing that invasive interviews. People I think like a lot. If they ask a question, I do answer the question. I'm not answering the question. Also just saying additionally important other stuff that I think is what you're really asking. Unless it's ip stuff. I don't try to. I was about to ask you that question. I say that? I say we don't share ip. Then it's not like I'm being coy with it. I'm just like. At what point would you say that I asked, what's the product? You probably have some vague, like, we're building an accountant. That's actually such a great question. Yeah, yeah. What do you want to say? So someone says, what does your product. This is actually a great question. I should have had a recording with this. That's actually such a great question. Someone goes, I haven't seen a demo of your product. What does it do? The first time someone asked me that question, I was like, to practice it. I was not ready for that. How much, Milo? Oh, no. I don't know. Okay, who wants to take it? Take your bracket. Value accruing to the model providers. OpenAI. I think in the context of an AI company, that's actually, like, a thing that people would consider a risk. It's like OpenAI nantropic. Just decide, hey, we can read and trade our models. We can rld them. We're just gonna buy, like, 10 engineers, and we're making whole product, and it's gonna be better. Okay, so that's actually another question we bought. Maybe we should touch on. That question at time also, because that's another great one. But we'll get to that one in a second. Answering your last question. Where are the risks? He's not answering your next question. Oh, I don't know which one he's. I thought he was the risk that people. Oh, yeah. Start. We'll talk about a different question. Okay. Is that a risk you want to share with them? I would mention. I feel like that is. Well, I don't know. I think that is probably risk that they would be thinking about if it's an AI company. Definitely. I think most people who are evaluating like AI companies is an open question of where does the value go in an AGI. Yeah. I don't know if anyone's okay. But I do want to ask that question a second. Let's just go back to what is the product? Counting. Yeah. What do you want, boy? I haven't seen the product. What's the product? Yeah. Okay? At a high level basis is gold is to do anything than an accountant that human accountant would do. And so right now, we're focused on a very specific subset of an accountant's workflows. But over time, we obviously plan to expand to further workflows. And that there's a whole kind of market strategy. Around that. 's really how it would lead. And then maybe I would say, Maybe I would tie in how we're positioning our products to basically, as AI gets better. Already have as much context. Than these accounting firms have. So that. And then that kind of gets the visibility, I guess. Sorry. I just started answering as if I was going to answer. But wandered off. But okay. It's a good start, right? I like the first sentence a lot, which is Know I always say the same thing, which is like, we're building an accountant, we're not building a filming software. We want to do anything in person, we'll be able to do. Right. A very great start. Sorry. I was. Actually. I meant to answer in this minute. I got distracted. I was going to go into kind of like why our market is so ripe for disruption. I agree with that. But they asked what the product does. I'm open to that. But I think there's also thing like, they're asking a question which is. I mean, at the root of it, there's also, like, what does Chronic do? Like, I don't know. And that's one of my core questions. I think that one, they're just asking the question, which is totally fair question. There's not maybe a deeper meaning behind that one? And so those ones you have to answer directly. It's like someone saying, like, well, I like my job. It's a very direct question, and you have to answer that question as opposed to talking about something else, which I've seen a lot sometimes. It just. Asking, like, 100 questions. And I couldn't understand what the root question was. You'd answer one question, you'd ask another question, answer that question. Yes. And it's like. And I couldn't find the theme in it. And at some point, I realized I was like, oh, you want to be rich? And he goes, yes. And I go. How much do you money? How much money do you want? And he goes $22 million. 22. And I said, oh, so you were just asking me, will I make $22 million? And that was the question. Everything else was bullshit. Every other question was some vague, hidden I highly recommend the book. Never split the difference. For this kind of stuff, but there were some hidden question. I was, like, sitting there, like, four hours into the thing because you got an offer, but he was not closing. Whatever. And at some point I was like, oh, that's what he wants. He wants $22 million. So his question is, will you make me $22 million? And then it's like, oh, wait for me to answer that question. I would answer vastly differently. Than every other. Like, he's asking tam, and we answer the TAM question. So he's like, market sizing. And he's like, at some point, it just never ended. And then at that point, that set of questions ended. Because that was the point. Of the question. And so all that to say, like, sometimes it takes a while to use a lot, you know, but, like, he wants 20 miles. Then it's like, oh, let's make it 20. Just trying to do some math on there. Do you say yes. Yeah. I mean, look, I said. I said look. I was like, oh, that's kind of reasonable. But I was like, look, it's just a function of valuation, equity, share and whatever, right? So the question is. It's not about. Is the tam. What's the tam? Right. Like the TAM doesn't matter. The question is, will he hit the valuation number required for you to make $22 million? Right. Which would mean that will we hit some revenue number as a percentage of that? That would make us the $22 million. And the question is, what's the likelihood that we would hit that revenue number? Right. I think that add on a real estate company, for most of us, that number is very high and also achievable. So I believe we can do it. And now the question is, do you believe that? Apparently not. He sent me this whole thing. His wife. I remember. Okay, it's fine. So anyways, my point is. So there's a poor question. Sometimes I think that the product. Is costing or anyone else. What is the product too? Can I ask when people come to an on site, can I start telling them, like, what I actually work on? Because they start to say, like, well, what do you each work on? Like, me and Ashley in a room, and it feels like, very dodgy to just be like, well, we ought to make accounting. I've been saying more specifically, but I didn't know that we weren't supposed to. Well, I think. I don't know. Until we become more and more transparent. Transparency over time. Like at the end of the onsite is when they get a demo, and that must mean we like them. You know, we don't give Thanos people we don't like. So by then it's full transparency, right at that point. Okay? I feel like you can only dodge questions. For so long before they start to feel like you were just. No, no, no, no. That's a lot on sites are different. You can maybe talk about on site, interview, how to converse, but I think you guys have been fine. I think in onsites also, I think. I don't say who, but someone was like, what do you do? And they were like, oh, I'm an engineer. It was definitely me. And so again, they're asking, what do you do? What they're really saying, do you like your job? What is this exciting? And so there's an opportunity again. To relate your personal experience of what you experience of working here is like not just literally answering the question. I'm a product engineer. Who works on workflow product. That's definitely what you. I'm not saying you said this. You're not the first guy. But it doesn't matter who said it, because we've all done it at some point. And not even just that question, but a variation of that question, right? That's the question. You just answered directly. When there's an opening and an opportunity to share even more than that. Right. So in your example, I'm just making this out, but you could say something like, we actually just built a product that takes an arbitrary request from accountants and can do stuff like breathing Excel files, creating PDFs, sending whatever emails, write journal entries. We are able to do so much of tax and audit. And classical accounting during that product. And so I lead all the product development for that product. You just say that? And that sounds kind of cool. I think I've been giving some very bad answer, I think, with that question. The thing that I think I struggle less with now, but definitely struggled more with before, still a little bit now. Is how much can I say? Because if the conversation continues, can I say the word casp? Yeah. Okay. This is a good point about reason to be having such I'm clearly. Question. So on the first interview, which is something that Ashley and I are doing now, but over time, We'll want other people to do. Which is where you first doing a technical assessment with them. I try to keep it vague. Ish. In that I say the word cas. That's fine. I think we have it on our website. I simply say words. You can say website. That we publish or share somewhere. And beyond that, a lot of metaphors. Like a lot of metaphors. I have a lot of adverse. Or I'll keep a big like we're building an accountant. And I kind of, as a person. So our goal is very simple. Anything you would say to a person, we should be able to do. We break that problem into a bunch of chunks. One chunk of it is that we need to understand all the things that a person can do. What are all the possible things that an accountable do? Two, we'd have to model that universe possibilities. Like I say, one way of model, one universe, parts of two. We have to then teach an AI how to navigate that. More of possibilities. So we have to teach it. Like, oh, here's how you send an email. Here is that you're doing an Excel file or whatever. State's big stuff. 3 One of the things I always say is interacting with intelligence. We don't know what that looks like. What elect have a coworker. We know that accounting is not purely a challenger face. There has to be some mechanism through which we interact with this intelligent thing that we're creating. And four, we need to be able to scale up this entire mechanism. To serve the 3 million accounts in the US and so I would bucket that into those four problems. And that's all I say. So what's the interface? What? What's the interface? I don't have tasks and stuff. You know, like that's some different interface. We made that up. Yeah, sorry. I'm asking as though I am the candidate. Well, I would say this. Okay. What's the interface? Right. That's true. Do you want me to answer? Am I doing a sample now? Okay, yes. You ask my standard basis. Well, one of the things we want to focus on. Is month interfaces to be familiar to people. Right. We want things that don't look so crazy. That people don't know how to use it. That would be hard. User experience. So one of the things, for example, is it's just sample changing. They say Sample methods, sample interfaces. Every accountant has a to do list. They say, hey, you know, we have a list of things we need to get done. And they just keep it to rule somewhere. So we made a to do list. Very simple, very similar interface, except the list is done. Right. And so that always gets people. Like Hangout. It's a simple interface, except the entire list is done. Three weeks of work. Just. Don't. And so that would be one way. We'd build a specific interface, the underlying intelligence for that. View is all the same across all these different interfaces. But that's one way we think our market closed and saved you like that. It didn't really give up that much information. But I think maybe I should just. I mean, this white. I mean, I don't use the word czechosrex personally. And I. Even if someone says it, I kind of like it's not. I mean, honestly, the. It doesn't matter if it's Checklist or Rex. That's a whole pitch. I think it's part of our pitch. But it's like it doesn't matter if it's checklist directs or pass or whatever. You give us work, we do work. All. Whatever you want. Today's checklist and Rex tomorrow might be something else. We're always discovering the way to manage work. The best, but it's less, you know? But we do the work. Right. And so we're submitting. Good. Never seen what accountants do? That's, like, not super. Yeah, that's why I like to do list as a example. Because the to do list we all have to deal with. In some way, shape or form. We're not giving away anything. You know, but I'm just saying, like, something like, you know, like, it's like them in with. You can use the reference. You know, that makes sense to me. Do you ever say, like, what if someone asks, who are your customers? Like, not literally, like, name your customers, but, like, what. What kind of business did you say we go for? Enterprise accounting firms. The largest accounting firms in the country. Okay, cool. Don't say what large means. And it doesn't want to have it. But we say we go for the biggest accounting firms of country over the last. Why do you think that that's the market segment? You answered that question. Yeah. Yeah. Answer every question to the best I know. Also, I will note this. When actually this is such a good point. When in an interview, someone asked you a question, you can always back and say, you know what? I'm actually not sure if I'm allowed to share that. Or. Not. But as you go along the interview, we're happy to help. Or if you can send me an email I'm happy to connect with all the time, this will happily answer that question. Say something like that. So you always have a fallback. If someone asked you the why, why do you sell to big accounting firms question, what would you say? What would I say to that? Specifically, why would you say that Question? Also, we don't have to stay on this forever. This is just something where whenever I get asked these questions or I'm the side of saying very little. Yeah, this, actually, I mean. There's, like, so many different things. I'm trying to think, and this is how I'd answer, by the way. If someone asked me about you. I think that enterprise accounting firms have the hardest problems. In the country. Right. And they also do mostly accounting for the. For the country. So if you can solve those problems, then selling to smaller accounting firms is easier. Following to corporations. Are easier. They also build a lot of trust. If I went to small accounting firms and solve their problems, I would be making, for instance. I sold problems were small accounting from South American pitch. But if I can solo prongs for big accounting firms and they go to smaller ones and say I have somewhere for the biggest economy in the world. They will immediately buy the software. Do the same with corporate, so it's a great expansion strategy. To start from. More than anywhere else. Makes sense. It feels like a good answer. Which actually kind of reminds me, maybe this is also just as. I mean, obviously you guys are feeling it, too. Where I've been here the longest. Right. And so I have a lot of knowledge. But also a lot of this knowledge has been shared. In docs and in our wiki and all these things. And I1, I would say just rereading all of those. If you guys, especially actively interviewing so that you get more familiar with just how we think in the process, I think it'll help you with your work, too. Like knowing the answer to that question is helpful for building stuff. Right. Like I personally think. I mean, this is how I was trained as an engineer, which is that study all the business context. Just for engineering purposes. Right, and go to market strategy, marketing, recruiting strategy, all these other things. And then use all the knowledge to code. And the way you code end up changing because you know what? We have all that information. Are there any high level numbers we are allowed to share? I feel like there are really, really common questions. That are like, what's the size of the team, how many engineers. What's your revenue numbers like? Are any of those shareable? Yeah. Team size is shareable. Revenue numbers we do not share. Sometimes I've had issues. Sometimes when I. By the way, also, another part of the process is someone asks you a question, you'll go, I don't know, maybe they'll come find me after they review. So you'll find out the answer to that question. So you can say, so there were times. Earlier, especially where I was asked to say take advantage, like what am I allowed to share? Putting down also asked Madam Mitch what she wanted to share instead of sharing. As for permission of forgiveness of the rv. And also we have forgiveness. For example, sometimes I say we make millions. But then I. Now I say a lot. Honestly, this is my experience in the interview process so far. With the people. We've gotten so far. Revenue have not been one of the questions that has been asked about a much like we talk about. I kind of think I don't know what's happening. I mean, are like number of users. Number of these people don't share. A bunch of different ways. Yeah, yeah. But, like, my last company because, like, they were training, like, a lot of people to do interviews. They, like, give the interview. Doc had, like, the three numbers. You're allowed to share. And they were like any other number they can ask for. You can try and redirect it to these three, or you say it's confidential. And that I thought that was, like, really helpful. So, like, we don't talk about revenue, but we're willing to talk about a number of customers. Or we don't talk about a number of users. That are willing to talk about a number of customers. Interesting. Yeah, I one can be really clarifying. I understand we might not be big enough to do that yet, but I would really recommend it. I think it was really helpful. To the interviewers. Yeah, the idea of an interview doc and so I didn't know that existed. I've never worked at a real company. That sounds like a great idea. We should have an interview, Doc. And then it can also be kept up to date. You know, we hit 50 employees, we're like celebrate right in the Matthew. That app was baby. Okay, no, that's. That's. That's a great idea. We shouldn't need to be done. And then it's really simple, right? Like anybody has a question, you're just like. But it's not one of those three. Super easy to remember. I mean, honestly, I don't share any. Numbers. Beyond. Team size, I think. I see a lot. But I also. Actually, I would say this. I think it might be helpful. Maybe I'll share some of my fireflies. With you. I don't know how to do this. But if you guys have time to listen to my introductory talk, I now have a down pat, but I'm essentially pre answering a lot of questions. I have time. Okay, so that's why my introduction. Probably two, two and a half minutes. But by one pre answering all of them. People feel more relaxed. I think they know a lot more than being. Then they have to spend all their energy, like, trying to squeeze in questions and try to get information. Like, somehow I just give up all the information. But by almost giving me all the information I had of time. People don't actually have that many questions. That they have. And so the revenue answer, for example, I answer a lot. I always answer it ahead of time. So that no one actually ends up asking it. You do. I do. Thank you. I remember that. Yeah, yeah, yeah. Because I think. Yeah. I just think. The more we can answer. It also helps. I think people like it a lot more when just giving up a lot of information. All the information can give up. Just give up ahead of time. You know, and then that way, like, sometimes I'll say, like, we're 11 people, and that already sets that excitement. I go, yeah. And, like, we're focusing on all these different. I don't know if I did a good job with it today. But yeah. I thought you had it down. Oh, well, sometimes when I take a break from any reason, I'm like, what do I say again? I hit a lot of. You can do the Joshua. I know. Good job. With josh. That's a great question. Every pre Christian hustle gives you another 16 digits that were OpenAI API keys exactly. Okay, so I'm gonna set to go in two minutes. Just heads up. Okay? I'll play my intro, and then you guys. I think this happens in two minutes. I was the second employee. Over two years now. Before joining basis, I work for a lot of startups. Build products. For companies coming from Placey to cacd, mostly as a consultant. I was. I've done that for about 20 or so companies. Both products. I've been a VC back founder before for a hedge fund data with its platform. But Samuel didn't have pmf. It's still going on, but I didn't think it was gonna work out. We ended up leaving, went back to consulting, and then randomly met Madam Mitch and I found them really refreshing. After speaking of hundreds of founders, I thought they had a very clear vision of what they were trying to do and how the world was gonna change because of this thing called AI, Which I knew nothing about it, and I think they were buying much, right, to be honest. And then, you know, they also were very systematic in company building. They had a lot of convictions. They had beliefs. They knew what they knew, they knew what they didn't know. They were all trying to find that if they didn't know. And do what they do, which was not how. This is how I work generally, which I really appreciated and we don't like culturally, but it's not how I see Startup friend, which is everyone's just trying to make money somehow. Anyway, please pivot 100 times. Please give me money. Yet, so it's nice to see a very systematic approach. Ended up joining. And I think the last thing we land on is, like, the kind of people we love working with and studying cars, each other. People. What do we think leadership means? What do we think management means? Or leading those hardships they actually allow but they didn't tell that I'm a lot of good things. There. With all that? We kind of built the foundation of a company over the last two and a half years. We have now. It's like something 40 something people. Just crazy because there is four people in room at some point. And we built an AI out. And this AI account to the loophole can do about the estimate, 60% accounting work that exists out there. We didn't do. It was more like 10, and which we've done a lot this year. And by the end of the year, we want to hit like, 90. Well on our way to them. And we sell this AI content to accounting firms who are experiencing a labor shortage. There's not a kid want to do that job and get those. They're aging out. And so we say, hey, look, we'll augment this. Kind of missing labor force. That you guys are struggling with and we'll tend into existing people and so the accounting might be held to them ends up saving them a few days time. Josie with generalism revenue, which makes them really, really happy. And they pay us a lot of money, which makes me really happy. And so things will be well. You know, in our goal of building an AI accountant, like building an accountant, which is almost like building a person, is a very, very hard job. There's so much work to do in terms of AI infrastructure. Product features and experiences like how do we interact with intelligence is still kind of clear domain field. Scaling up our day detail pipelines, investing more in tested logging, modern alerts, emails and you know, there's, there's so much work to do and we are 11 people. We test the code base and we are completely outnumbered or whatever, the number of projects, the number of people ratio, way out. We survive and we take it on. But we would really appreciate the help from folks who really want to come in on different areas of business and take on huge problem spaces to help build 100 billion business around them. That's kind of why we're speaking. So that answers a lot of questions. Wasn't my best. But who was that with Josh? Yeah, that's. That's not my. Yeah. It was okay. Your best around the can be really good about sharing, like, what it's like. Our standard numbers we share is, like, do we like to talk about, like, what the fundraise was, or do we find that, like, doesn't sell this to our best? Like. And then how we like to think about our value. Because that's a really common. And, like, easily. You need to find numbers so that you know. We could go to that, or we could say, like. Actually, we don't really like that. You know? Perspective on the business. Yeah, I think, you know, I will. Maybe I'll end the year on this interview because I got to go to Monday. Okay? I learned on this note, and I've shared this video, so I guess I'll share it to large group, you know? I would like an interview. Dr. You can. You can say about some of the things you can and can't say, but I think that maybe I'll end on this, like the final, like, at the end of the day. Like in an interview. I really want people to show up as them where they're at. You know, my worry with any reduction is like, when they're saying the same thing. Starts with humanity of the thing. Like, I really want us to show up as people. You know? You're like, hi, I'm Connor. Like this is my experience. Basis. And in a lot of ways, it's like you're saying, do I want to work with this person? And they're saying, do I want to work with con or not even basis? Connor and for them to really gauge if they want to work with Connor and Connor show up as congratulate as interview work. You know, and so there are some, like, rules and guidelines. Of like what numbers you can share. What numbers you can't share and what side of the product and whatnot. But beyond all that. It's just them getting to know you. Like, the way I think about a lot of interviewing is like, if you. If you're at a party, And someone said, like, what do you do? You would still can't talk about certain things, and you can't say certain things. Like there aren't things you can't say. There are things you can say. But beyond that, it's a free blown conversation. They can ask you questions. You can ask them questions. It has a lot of things. It is recruiting. So there's some set of questions you're trying to answer. Question, ask. But you're also trying to let them, you know, participate in a flow of conversation. And so that's why I don't like to give predefined interview questions. Because you feel what's right to you in that moment. You don't like to predefined even our problem solutions like airport or these other things. Like there's not necessarily a correct way to do them or incorrect way to do them. You're just picking a topic and spending 30 minutes on them. You know, I always. I've been saying this. I also. I would say interviewing is a skill. So you're always practicing how to get better. Right? So each time you do it, just take, you know, feel it when, like, you say something, you know. But over time, you'll get better at that skill. So I'm still improving my interviewing skills. As I have been philosophers, I'm always iterating. So, like, one thing, for example, I've been saying, which I think has been resonating well, is I say the theme of the error is at basis as a whole. Is, what would it be like to work next to this person? That's what we're always checking. So I said this at the beginning. I say we roll around in chairs and share ideas with each other and talk all day long so we try to recreate that experience. It's like moments in the office. Are called it. You know, so this part of the interview is a moment, one of the offices. You, our eye roll over in a chair next to you, say, I got my. And, like, we're just trying to recreate what it would be like to sit next to. So that's something I've been starting to say, and. I'm not saying anyone here has to say that, but as I'm iterating and saying different things, like that just came one day and I was, like, kind of nice. Like, I'm kind of now more standard practice to say that. And then that also alleviates a lot of pressure from people, I feel, because they don't have to feel like they have to pass a test. More like we're actually gonna work together. So let's see. What? And I feel people calm down a little bit more, which is often what I try to do in interviews because, like, people feel so, like, tight that, like, it takes a little bit to come to now so I can actually see who they are. Because their tightness. I can't see who they are. And so, yes, there will be guidelines, and I think you're right. Chelsea. To. To note some of them. But you can all make this your own. In a lot of ways. I trust all of you guys as different judgments, and everyone's gonna have different perspectives. And different views on it. At the end of it, we all have to like them anyways. So, like it won't matter. So, yeah, that's more. Just something to note. So that's why I don't want to structure it too direction, you know, in an airport. Like for those investing airport. Calls me chelsea. I was looking at Chelsea as I look. You guys have asked me different habits, too. At least. But, yeah. So I. That's just the final note. So I think that's also what I mean, honestly, I think what makes our movie so special is people believe they're going. I just talk to a person. You know, not like someone who's trying to test me and test my intellect and see if I'm good enough. And like, I personally believe every person smart. And every person is passionate about something, and if those whatever they're good at and whatever they're smart about, if that aligns with the kind of things we need and culturally, that's great. And if not, it's not. And, like, we don't have to test people. Out. I think everyone's good enough. So that I say that sometimes in the beginning to just alleviate people from the pressure to perform. Which you know. Some people take on it. And so, yeah, that's. That's where I just say, like, as you guys are talking to folks, like, there's, you know. On the. Loose guidelines, Mitch, Dave. People who are learning how to read it. Like a list of things they can. And can't say. At some point. We'll make a list. Anything else. All right. 